{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Flaml library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing library AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_setting = {\n",
    "    \"time_budget\":10,\n",
    "    \"metric\":'accuracy',\n",
    "    \"task\":'classification',\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 10-12 13:44:33] {1432} INFO - Evaluation method: cv\n",
      "[flaml.automl: 10-12 13:44:33] {1478} INFO - Minimizing error metric: 1-accuracy\n",
      "[flaml.automl: 10-12 13:44:33] {1515} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'lrl1']\n",
      "[flaml.automl: 10-12 13:44:33] {1748} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:33] {1865} INFO - Estimated sufficient time budget=840s. Estimated necessary time budget=15s.\n",
      "[flaml.automl: 10-12 13:44:33] {1938} INFO -  at 0.3s,\testimator lgbm's best error=0.0733,\tbest estimator lgbm's best error=0.0733\n",
      "[flaml.automl: 10-12 13:44:33] {1748} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:33] {1938} INFO -  at 0.4s,\testimator lgbm's best error=0.0733,\tbest estimator lgbm's best error=0.0733\n",
      "[flaml.automl: 10-12 13:44:33] {1748} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:33] {1938} INFO -  at 0.5s,\testimator lgbm's best error=0.0533,\tbest estimator lgbm's best error=0.0533\n",
      "[flaml.automl: 10-12 13:44:33] {1748} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:33] {1938} INFO -  at 0.5s,\testimator lgbm's best error=0.0533,\tbest estimator lgbm's best error=0.0533\n",
      "[flaml.automl: 10-12 13:44:33] {1748} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:33] {1938} INFO -  at 0.5s,\testimator lgbm's best error=0.0533,\tbest estimator lgbm's best error=0.0533\n",
      "[flaml.automl: 10-12 13:44:33] {1748} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:33] {1938} INFO -  at 0.6s,\testimator lgbm's best error=0.0467,\tbest estimator lgbm's best error=0.0467\n",
      "[flaml.automl: 10-12 13:44:33] {1748} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:33] {1938} INFO -  at 0.6s,\testimator lgbm's best error=0.0467,\tbest estimator lgbm's best error=0.0467\n",
      "[flaml.automl: 10-12 13:44:33] {1748} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:33] {1938} INFO -  at 0.6s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-12 13:44:33] {1748} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:33] {1938} INFO -  at 0.7s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-12 13:44:33] {1748} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:33] {1938} INFO -  at 0.7s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-12 13:44:33] {1748} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:33] {1938} INFO -  at 0.8s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-12 13:44:33] {1748} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:33] {1938} INFO -  at 0.8s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-12 13:44:33] {1748} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:33] {1938} INFO -  at 0.9s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-12 13:44:33] {1748} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:34] {1938} INFO -  at 0.9s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-12 13:44:34] {1748} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:34] {1938} INFO -  at 1.0s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-12 13:44:34] {1748} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:34] {1938} INFO -  at 1.0s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-12 13:44:34] {1748} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:34] {1938} INFO -  at 1.1s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-12 13:44:34] {1748} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:34] {1938} INFO -  at 1.1s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-12 13:44:34] {1748} INFO - iteration 18, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:34] {1938} INFO -  at 1.2s,\testimator extra_tree's best error=0.0533,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-12 13:44:34] {1748} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:34] {1938} INFO -  at 1.3s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-12 13:44:34] {1748} INFO - iteration 20, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:34] {1938} INFO -  at 1.4s,\testimator extra_tree's best error=0.0333,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:34] {1748} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:34] {1938} INFO -  at 1.5s,\testimator xgboost's best error=0.0600,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:34] {1748} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:34] {1938} INFO -  at 1.5s,\testimator xgboost's best error=0.0600,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:34] {1748} INFO - iteration 23, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:34] {1938} INFO -  at 1.6s,\testimator extra_tree's best error=0.0333,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:34] {1748} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:34] {1938} INFO -  at 1.7s,\testimator extra_tree's best error=0.0333,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:34] {1748} INFO - iteration 25, current learner rf\n",
      "[flaml.automl: 10-12 13:44:35] {1938} INFO -  at 2.0s,\testimator rf's best error=0.0467,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:35] {1748} INFO - iteration 26, current learner rf\n",
      "[flaml.automl: 10-12 13:44:35] {1938} INFO -  at 2.3s,\testimator rf's best error=0.0467,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:35] {1748} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:35] {1938} INFO -  at 2.5s,\testimator extra_tree's best error=0.0333,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:35] {1748} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:35] {1938} INFO -  at 2.9s,\testimator extra_tree's best error=0.0333,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:35] {1748} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:36] {1938} INFO -  at 3.1s,\testimator extra_tree's best error=0.0333,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:36] {1748} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:36] {1938} INFO -  at 3.2s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:36] {1748} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:36] {1938} INFO -  at 3.3s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:36] {1748} INFO - iteration 32, current learner rf\n",
      "[flaml.automl: 10-12 13:44:36] {1938} INFO -  at 3.4s,\testimator rf's best error=0.0467,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:36] {1748} INFO - iteration 33, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:36] {1938} INFO -  at 3.7s,\testimator extra_tree's best error=0.0333,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:36] {1748} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:36] {1938} INFO -  at 3.8s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:36] {1748} INFO - iteration 35, current learner rf\n",
      "[flaml.automl: 10-12 13:44:37] {1938} INFO -  at 4.0s,\testimator rf's best error=0.0467,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:37] {1748} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:37] {1938} INFO -  at 4.3s,\testimator extra_tree's best error=0.0333,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:37] {1748} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:37] {1938} INFO -  at 4.5s,\testimator xgboost's best error=0.0600,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:37] {1748} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:37] {1938} INFO -  at 4.5s,\testimator xgboost's best error=0.0533,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:37] {1748} INFO - iteration 39, current learner rf\n",
      "[flaml.automl: 10-12 13:44:37] {1938} INFO -  at 4.6s,\testimator rf's best error=0.0467,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:37] {1748} INFO - iteration 40, current learner rf\n",
      "[flaml.automl: 10-12 13:44:37] {1938} INFO -  at 4.9s,\testimator rf's best error=0.0467,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:37] {1748} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:38] {1938} INFO -  at 5.1s,\testimator extra_tree's best error=0.0333,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:38] {1748} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:38] {1938} INFO -  at 5.2s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:38] {1748} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:38] {1938} INFO -  at 5.3s,\testimator xgboost's best error=0.0533,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:38] {1748} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:38] {1938} INFO -  at 5.4s,\testimator extra_tree's best error=0.0333,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:38] {1748} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:38] {1938} INFO -  at 5.4s,\testimator xgboost's best error=0.0533,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:38] {1748} INFO - iteration 46, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:38] {1938} INFO -  at 5.4s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:38] {1748} INFO - iteration 47, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:38] {1938} INFO -  at 5.5s,\testimator xgboost's best error=0.0533,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:38] {1748} INFO - iteration 48, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:38] {1938} INFO -  at 5.5s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:38] {1748} INFO - iteration 49, current learner rf\n",
      "[flaml.automl: 10-12 13:44:38] {1938} INFO -  at 5.6s,\testimator rf's best error=0.0467,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:38] {1748} INFO - iteration 50, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:38] {1938} INFO -  at 5.7s,\testimator extra_tree's best error=0.0333,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:38] {1748} INFO - iteration 51, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:38] {1938} INFO -  at 5.8s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:38] {1748} INFO - iteration 52, current learner rf\n",
      "[flaml.automl: 10-12 13:44:39] {1938} INFO -  at 6.0s,\testimator rf's best error=0.0467,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:39] {1748} INFO - iteration 53, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:39] {1938} INFO -  at 6.0s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:39] {1748} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:39] {1938} INFO -  at 6.0s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:39] {1748} INFO - iteration 55, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:39] {1938} INFO -  at 6.1s,\testimator xgboost's best error=0.0533,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:39] {1748} INFO - iteration 56, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:39] {1938} INFO -  at 6.2s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:39] {1748} INFO - iteration 57, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:39] {1938} INFO -  at 6.2s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:39] {1748} INFO - iteration 58, current learner rf\n",
      "[flaml.automl: 10-12 13:44:39] {1938} INFO -  at 6.3s,\testimator rf's best error=0.0467,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:39] {1748} INFO - iteration 59, current learner catboost\n",
      "[flaml.automl: 10-12 13:44:40] {1938} INFO -  at 7.2s,\testimator catboost's best error=0.0467,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:40] {1748} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:40] {1938} INFO -  at 7.2s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:40] {1748} INFO - iteration 61, current learner catboost\n",
      "[flaml.automl: 10-12 13:44:40] {1938} INFO -  at 7.7s,\testimator catboost's best error=0.0467,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:40] {1748} INFO - iteration 62, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:40] {1938} INFO -  at 7.7s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:40] {1748} INFO - iteration 63, current learner catboost\n",
      "[flaml.automl: 10-12 13:44:41] {1938} INFO -  at 8.2s,\testimator catboost's best error=0.0467,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:41] {1748} INFO - iteration 64, current learner catboost\n",
      "[flaml.automl: 10-12 13:44:41] {1938} INFO -  at 8.8s,\testimator catboost's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:41] {1748} INFO - iteration 65, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:41] {1938} INFO -  at 8.9s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:41] {1748} INFO - iteration 66, current learner rf\n",
      "[flaml.automl: 10-12 13:44:42] {1938} INFO -  at 9.0s,\testimator rf's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:42] {1748} INFO - iteration 67, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:42] {1938} INFO -  at 9.1s,\testimator xgboost's best error=0.0533,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:42] {1748} INFO - iteration 68, current learner rf\n",
      "[flaml.automl: 10-12 13:44:42] {1938} INFO -  at 9.2s,\testimator rf's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:42] {1748} INFO - iteration 69, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:42] {1938} INFO -  at 9.3s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:42] {1748} INFO - iteration 70, current learner catboost\n",
      "[flaml.automl: 10-12 13:44:42] {1938} INFO -  at 9.3s,\testimator catboost's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:42] {1748} INFO - iteration 71, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:42] {1938} INFO -  at 9.4s,\testimator xgboost's best error=0.0533,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:42] {1748} INFO - iteration 72, current learner catboost\n",
      "[flaml.automl: 10-12 13:44:42] {1938} INFO -  at 9.4s,\testimator catboost's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:42] {1748} INFO - iteration 73, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:42] {1938} INFO -  at 9.5s,\testimator extra_tree's best error=0.0333,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:42] {1748} INFO - iteration 74, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:42] {1938} INFO -  at 9.5s,\testimator xgboost's best error=0.0533,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:42] {1748} INFO - iteration 75, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:42] {1938} INFO -  at 9.6s,\testimator extra_tree's best error=0.0333,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:42] {1748} INFO - iteration 76, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:42] {1938} INFO -  at 9.6s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:42] {1748} INFO - iteration 77, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:42] {1938} INFO -  at 9.7s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:42] {1748} INFO - iteration 78, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:42] {1938} INFO -  at 9.8s,\testimator extra_tree's best error=0.0333,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:42] {1748} INFO - iteration 79, current learner rf\n",
      "[flaml.automl: 10-12 13:44:43] {1938} INFO -  at 9.9s,\testimator rf's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:43] {1748} INFO - iteration 80, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:43] {1938} INFO -  at 10.0s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:43] {1748} INFO - iteration 81, current learner lrl1\n",
      "No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'.\n",
      "C:\\Users\\shikh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[flaml.automl: 10-12 13:44:43] {1938} INFO -  at 10.1s,\testimator lrl1's best error=0.0667,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-12 13:44:43] {2043} INFO - selected model: ExtraTreesClassifier(max_features=0.9692029582222275, max_leaf_nodes=6,\n",
      "                     n_estimators=4, n_jobs=-1)\n",
      "[flaml.automl: 10-12 13:44:43] {2104} INFO - retrain extra_tree for 0.0s\n",
      "[flaml.automl: 10-12 13:44:43] {2110} INFO - retrained model: ExtraTreesClassifier(max_features=0.9692029582222275, max_leaf_nodes=6,\n",
      "                     n_estimators=4, n_jobs=-1)\n",
      "[flaml.automl: 10-12 13:44:43] {1539} INFO - fit succeeded\n",
      "[flaml.automl: 10-12 13:44:43] {1540} INFO - Time taken to find the best model: 1.3875946998596191\n"
     ]
    }
   ],
   "source": [
    "#Training with labeled data\n",
    "X_train,y_train = load_iris(return_X_y = True)\n",
    "automl.fit(X_train = X_train,y_train = y_train,**auto_setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.99509804 0.00490196 0.        ]\n",
      " [0.         0.86754493 0.13245507]\n",
      " [0.         0.95782585 0.04217415]\n",
      " [0.         0.67636846 0.32363154]\n",
      " [0.         0.97772436 0.02227564]\n",
      " [0.         0.87970085 0.12029915]\n",
      " [0.         0.96383547 0.03616453]\n",
      " [0.         0.86754493 0.13245507]\n",
      " [0.         0.97772436 0.02227564]\n",
      " [0.         0.95782585 0.04217415]\n",
      " [0.         0.97772436 0.02227564]\n",
      " [0.         0.97772436 0.02227564]\n",
      " [0.         0.97772436 0.02227564]\n",
      " [0.         0.98733974 0.01266026]\n",
      " [0.         0.86754493 0.13245507]\n",
      " [0.         0.97772436 0.02227564]\n",
      " [0.         0.97171474 0.02828526]\n",
      " [0.         0.96383547 0.03616453]\n",
      " [0.         0.97772436 0.02227564]\n",
      " [0.         0.86233974 0.13766026]\n",
      " [0.         0.97772436 0.02227564]\n",
      " [0.         0.28292839 0.71707161]\n",
      " [0.         0.98733974 0.01266026]\n",
      " [0.         0.48713235 0.51286765]\n",
      " [0.         0.89236111 0.10763889]\n",
      " [0.         0.97171474 0.02828526]\n",
      " [0.         0.97171474 0.02828526]\n",
      " [0.         0.66441993 0.33558007]\n",
      " [0.         0.67636846 0.32363154]\n",
      " [0.         0.95782585 0.04217415]\n",
      " [0.         0.97772436 0.02227564]\n",
      " [0.         0.97772436 0.02227564]\n",
      " [0.         0.97772436 0.02227564]\n",
      " [0.         0.97772436 0.02227564]\n",
      " [0.         0.48713235 0.51286765]\n",
      " [0.         0.96383547 0.03616453]\n",
      " [0.         0.95782585 0.04217415]\n",
      " [0.         0.86754493 0.13245507]\n",
      " [0.         0.98733974 0.01266026]\n",
      " [0.         0.97772436 0.02227564]\n",
      " [0.         0.97772436 0.02227564]\n",
      " [0.         0.97772436 0.02227564]\n",
      " [0.         0.95782585 0.04217415]\n",
      " [0.         0.97772436 0.02227564]\n",
      " [0.         0.97772436 0.02227564]\n",
      " [0.         0.97772436 0.02227564]\n",
      " [0.         0.97772436 0.02227564]\n",
      " [0.         0.97772436 0.02227564]\n",
      " [0.         0.97171474 0.02828526]\n",
      " [0.24509804 0.73903658 0.01586538]\n",
      " [0.         0.97772436 0.02227564]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.06969309 0.93030691]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.85272436 0.14727564]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.06969309 0.93030691]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.06969309 0.93030691]\n",
      " [0.         0.06969309 0.93030691]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.48713235 0.51286765]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.06969309 0.93030691]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.21675192 0.78324808]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.28292839 0.71707161]\n",
      " [0.         0.21675192 0.78324808]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.234375   0.765625  ]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.59824346 0.40175654]\n",
      " [0.         0.28125    0.71875   ]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.28292839 0.71707161]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.06969309 0.93030691]\n",
      " [0.         0.06969309 0.93030691]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.06969309 0.93030691]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.01086957 0.98913043]\n",
      " [0.         0.21675192 0.78324808]]\n",
      "<flaml.model.ExtraTreeEstimator object at 0x0000024DFA7CD670>\n"
     ]
    }
   ],
   "source": [
    "#Prediction with the best model\n",
    "print(automl.predict_proba(X_train))\n",
    "print(automl.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML()\n",
    "automl_settings = {\n",
    "    \"time_budget\":10,\n",
    "    \"metric\":'r2',\n",
    "    \"task\":'regression'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 10-12 13:44:43] {1432} INFO - Evaluation method: cv\n",
      "[flaml.automl: 10-12 13:44:43] {1478} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 10-12 13:44:43] {1515} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree']\n",
      "[flaml.automl: 10-12 13:44:43] {1748} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:43] {1865} INFO - Estimated sufficient time budget=884s. Estimated necessary time budget=2s.\n",
      "[flaml.automl: 10-12 13:44:43] {1938} INFO -  at 0.1s,\testimator lgbm's best error=0.6257,\tbest estimator lgbm's best error=0.6257\n",
      "[flaml.automl: 10-12 13:44:43] {1748} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:43] {1938} INFO -  at 0.2s,\testimator lgbm's best error=0.6257,\tbest estimator lgbm's best error=0.6257\n",
      "[flaml.automl: 10-12 13:44:43] {1748} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:43] {1938} INFO -  at 0.2s,\testimator lgbm's best error=0.3498,\tbest estimator lgbm's best error=0.3498\n",
      "[flaml.automl: 10-12 13:44:43] {1748} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:43] {1938} INFO -  at 0.2s,\testimator lgbm's best error=0.2466,\tbest estimator lgbm's best error=0.2466\n",
      "[flaml.automl: 10-12 13:44:43] {1748} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:43] {1938} INFO -  at 0.3s,\testimator lgbm's best error=0.2466,\tbest estimator lgbm's best error=0.2466\n",
      "[flaml.automl: 10-12 13:44:43] {1748} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:43] {1938} INFO -  at 0.3s,\testimator lgbm's best error=0.2087,\tbest estimator lgbm's best error=0.2087\n",
      "[flaml.automl: 10-12 13:44:43] {1748} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:43] {1938} INFO -  at 0.4s,\testimator lgbm's best error=0.2087,\tbest estimator lgbm's best error=0.2087\n",
      "[flaml.automl: 10-12 13:44:43] {1748} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:43] {1938} INFO -  at 0.4s,\testimator lgbm's best error=0.2087,\tbest estimator lgbm's best error=0.2087\n",
      "[flaml.automl: 10-12 13:44:43] {1748} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:43] {1938} INFO -  at 0.5s,\testimator lgbm's best error=0.1682,\tbest estimator lgbm's best error=0.1682\n",
      "[flaml.automl: 10-12 13:44:43] {1748} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:43] {1938} INFO -  at 0.5s,\testimator lgbm's best error=0.1682,\tbest estimator lgbm's best error=0.1682\n",
      "[flaml.automl: 10-12 13:44:43] {1748} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:43] {1938} INFO -  at 0.6s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:43] {1748} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:43] {1938} INFO -  at 0.6s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:43] {1748} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:44] {1938} INFO -  at 0.7s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:44] {1748} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:44] {1938} INFO -  at 0.8s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:44] {1748} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:44] {1938} INFO -  at 0.8s,\testimator xgboost's best error=3.1930,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:44] {1748} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:44] {1938} INFO -  at 0.8s,\testimator xgboost's best error=3.1930,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:44] {1748} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:44] {1938} INFO -  at 0.9s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:44] {1748} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:44] {1938} INFO -  at 1.0s,\testimator xgboost's best error=0.8686,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:44] {1748} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:44] {1938} INFO -  at 1.0s,\testimator xgboost's best error=0.2853,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:44] {1748} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:44] {1938} INFO -  at 1.0s,\testimator xgboost's best error=0.2853,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:44] {1748} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:44] {1938} INFO -  at 1.1s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:44] {1748} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:44] {1938} INFO -  at 1.2s,\testimator xgboost's best error=0.2722,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:44] {1748} INFO - iteration 22, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:44] {1938} INFO -  at 1.3s,\testimator extra_tree's best error=0.3466,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:44] {1748} INFO - iteration 23, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:44] {1938} INFO -  at 1.3s,\testimator extra_tree's best error=0.2145,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:44] {1748} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:44] {1938} INFO -  at 1.5s,\testimator extra_tree's best error=0.2145,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:44] {1748} INFO - iteration 25, current learner rf\n",
      "[flaml.automl: 10-12 13:44:45] {1938} INFO -  at 1.8s,\testimator rf's best error=0.2900,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:45] {1748} INFO - iteration 26, current learner rf\n",
      "[flaml.automl: 10-12 13:44:45] {1938} INFO -  at 2.0s,\testimator rf's best error=0.2138,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:45] {1748} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:45] {1938} INFO -  at 2.3s,\testimator extra_tree's best error=0.1711,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:45] {1748} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:45] {1938} INFO -  at 2.6s,\testimator extra_tree's best error=0.1694,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:45] {1748} INFO - iteration 29, current learner rf\n",
      "[flaml.automl: 10-12 13:44:46] {1938} INFO -  at 2.9s,\testimator rf's best error=0.2138,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:46] {1748} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:46] {1938} INFO -  at 3.0s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:46] {1748} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:46] {1938} INFO -  at 3.1s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:46] {1748} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:46] {1938} INFO -  at 3.2s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:46] {1748} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:46] {1938} INFO -  at 3.2s,\testimator xgboost's best error=0.2510,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:46] {1748} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:46] {1938} INFO -  at 3.3s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:46] {1748} INFO - iteration 35, current learner rf\n",
      "[flaml.automl: 10-12 13:44:46] {1938} INFO -  at 3.4s,\testimator rf's best error=0.1937,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:46] {1748} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:46] {1938} INFO -  at 3.5s,\testimator xgboost's best error=0.2510,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:46] {1748} INFO - iteration 37, current learner rf\n",
      "[flaml.automl: 10-12 13:44:46] {1938} INFO -  at 3.6s,\testimator rf's best error=0.1678,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:46] {1748} INFO - iteration 38, current learner rf\n",
      "[flaml.automl: 10-12 13:44:47] {1938} INFO -  at 3.8s,\testimator rf's best error=0.1678,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:47] {1748} INFO - iteration 39, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:47] {1938} INFO -  at 4.0s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:47] {1748} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:47] {1938} INFO -  at 4.1s,\testimator xgboost's best error=0.2510,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:47] {1748} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:47] {1938} INFO -  at 4.1s,\testimator xgboost's best error=0.2328,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:47] {1748} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:47] {1938} INFO -  at 4.2s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:47] {1748} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:47] {1938} INFO -  at 4.3s,\testimator xgboost's best error=0.2180,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:47] {1748} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:47] {1938} INFO -  at 4.4s,\testimator extra_tree's best error=0.1607,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:47] {1748} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:47] {1938} INFO -  at 4.5s,\testimator extra_tree's best error=0.1607,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:47] {1748} INFO - iteration 46, current learner rf\n",
      "[flaml.automl: 10-12 13:44:48] {1938} INFO -  at 4.8s,\testimator rf's best error=0.1678,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:48] {1748} INFO - iteration 47, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:48] {1938} INFO -  at 4.9s,\testimator xgboost's best error=0.2180,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:48] {1748} INFO - iteration 48, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:48] {1938} INFO -  at 5.0s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:48] {1748} INFO - iteration 49, current learner rf\n",
      "[flaml.automl: 10-12 13:44:48] {1938} INFO -  at 5.1s,\testimator rf's best error=0.1678,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:48] {1748} INFO - iteration 50, current learner extra_tree\n",
      "[flaml.automl: 10-12 13:44:48] {1938} INFO -  at 5.3s,\testimator extra_tree's best error=0.1607,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:48] {1748} INFO - iteration 51, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:48] {1938} INFO -  at 5.5s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:48] {1748} INFO - iteration 52, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:48] {1938} INFO -  at 5.6s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:48] {1748} INFO - iteration 53, current learner catboost\n",
      "[flaml.automl: 10-12 13:44:51] {1938} INFO -  at 7.7s,\testimator catboost's best error=0.1454,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:51] {1748} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:51] {1938} INFO -  at 7.9s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:51] {1748} INFO - iteration 55, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:51] {1938} INFO -  at 8.0s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:51] {1748} INFO - iteration 56, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:51] {1938} INFO -  at 8.0s,\testimator xgboost's best error=0.1882,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:51] {1748} INFO - iteration 57, current learner rf\n",
      "[flaml.automl: 10-12 13:44:51] {1938} INFO -  at 8.2s,\testimator rf's best error=0.1678,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:51] {1748} INFO - iteration 58, current learner rf\n",
      "[flaml.automl: 10-12 13:44:51] {1938} INFO -  at 8.4s,\testimator rf's best error=0.1678,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:51] {1748} INFO - iteration 59, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:51] {1938} INFO -  at 8.5s,\testimator xgboost's best error=0.1882,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:51] {1748} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:51] {1938} INFO -  at 8.6s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:51] {1748} INFO - iteration 61, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:51] {1938} INFO -  at 8.6s,\testimator xgboost's best error=0.1822,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:51] {1748} INFO - iteration 62, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:52] {1938} INFO -  at 8.7s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:52] {1748} INFO - iteration 63, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:52] {1938} INFO -  at 8.7s,\testimator xgboost's best error=0.1822,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:52] {1748} INFO - iteration 64, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:52] {1938} INFO -  at 8.8s,\testimator xgboost's best error=0.1621,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:52] {1748} INFO - iteration 65, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:52] {1938} INFO -  at 8.9s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:52] {1748} INFO - iteration 66, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:52] {1938} INFO -  at 8.9s,\testimator xgboost's best error=0.1621,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:52] {1748} INFO - iteration 67, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:52] {1938} INFO -  at 9.1s,\testimator xgboost's best error=0.1514,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:52] {1748} INFO - iteration 68, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:52] {1938} INFO -  at 9.2s,\testimator xgboost's best error=0.1514,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:52] {1748} INFO - iteration 69, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:52] {1938} INFO -  at 9.3s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:52] {1748} INFO - iteration 70, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:52] {1938} INFO -  at 9.6s,\testimator xgboost's best error=0.1514,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:52] {1748} INFO - iteration 71, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:53] {1938} INFO -  at 9.7s,\testimator xgboost's best error=0.1514,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:53] {1748} INFO - iteration 72, current learner xgboost\n",
      "[flaml.automl: 10-12 13:44:53] {1938} INFO -  at 9.9s,\testimator xgboost's best error=0.1514,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:53] {1748} INFO - iteration 73, current learner lgbm\n",
      "[flaml.automl: 10-12 13:44:53] {1938} INFO -  at 10.0s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-12 13:44:53] {2043} INFO - selected model: LGBMRegressor(colsample_bytree=0.6649148062238498,\n",
      "              learning_rate=0.17402065726724145, max_bin=128,\n",
      "              min_child_samples=3, n_estimators=32, num_leaves=9,\n",
      "              objective='regression', reg_alpha=0.0009765625,\n",
      "              reg_lambda=0.006761362450996489, verbose=-1)\n",
      "[flaml.automl: 10-12 13:44:53] {2104} INFO - retrain lgbm for 0.0s\n",
      "[flaml.automl: 10-12 13:44:53] {2110} INFO - retrained model: LGBMRegressor(colsample_bytree=0.6649148062238498,\n",
      "              learning_rate=0.17402065726724145, max_bin=128,\n",
      "              min_child_samples=3, n_estimators=32, num_leaves=9,\n",
      "              objective='regression', reg_alpha=0.0009765625,\n",
      "              reg_lambda=0.006761362450996489, verbose=-1)\n",
      "[flaml.automl: 10-12 13:44:53] {1539} INFO - fit succeeded\n",
      "[flaml.automl: 10-12 13:44:53] {1540} INFO - Time taken to find the best model: 0.5730984210968018\n"
     ]
    }
   ],
   "source": [
    "#Training with labeled data\n",
    "X_train,y_train = load_boston(return_X_y = True)\n",
    "automl.fit(X_train = X_train,y_train = y_train,**automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25.85426879 22.17737651 33.79509964 33.47189557 35.61127167 26.6926382\n",
      " 21.53656446 20.99173684 16.18673463 18.75433976 18.20961633 20.48286627\n",
      " 20.20745331 19.5131759  18.82401423 19.81864373 21.91420674 17.53721008\n",
      " 18.69698259 19.07769813 14.3021372  18.32367106 16.63348583 15.34809335\n",
      " 16.27978499 15.13176242 16.94561436 15.20221211 18.67737191 20.75076542\n",
      " 13.88486622 17.70376242 13.89318927 14.90744983 14.32837615 21.02020963\n",
      " 20.89410764 21.52937191 23.19568492 30.3824402  34.45306735 29.43834549\n",
      " 24.62262048 24.62262048 22.21884844 20.87353145 20.36481607 18.09945043\n",
      " 15.55273032 18.67322033 20.4058421  21.53510487 24.1301244  21.73345138\n",
      " 17.74586736 34.48285914 23.17178682 31.55632404 23.26235097 20.39233374\n",
      " 18.98627393 17.89811291 22.71262836 25.23349363 32.76974079 25.04432847\n",
      " 19.83367435 20.94710592 19.92700235 21.23614492 23.62275307 21.08771163\n",
      " 22.31713619 23.46816704 24.39319272 22.93449232 21.05889974 21.25605159\n",
      " 21.17094097 21.4104049  26.32531539 24.84165632 23.41875466 22.8120377\n",
      " 23.12681643 26.07314549 21.34032521 22.59488629 26.81601064 30.10072674\n",
      " 23.47133879 22.62450376 23.40848205 25.20150116 20.74313622 26.63582822\n",
      " 22.56394496 40.98684448 43.03722064 33.01766391 24.84190574 25.43455857\n",
      " 18.18875737 20.49979008 20.57478854 18.13734457 17.91303198 20.49979008\n",
      " 20.57478854 18.8322359  21.11833105 22.96406162 18.57150096 18.83508569\n",
      " 20.89066811 18.58619509 20.95795201 20.4381487  18.58619509 20.72664127\n",
      " 21.62721157 21.09344795 19.51757484 17.53599996 19.51757484 19.78584094\n",
      " 17.36958717 16.39253423 16.86856532 15.853506   19.71749942 19.35197602\n",
      " 20.07005987 17.39965131 15.92640822 17.14455857 16.51379168 18.47224498\n",
      " 14.38445978 16.3202417  14.36742357 13.09473563 14.46737843 14.73422787\n",
      " 13.79400434 15.41208419 17.4578433  13.90794056 14.77126156 15.18245573\n",
      " 20.57464694 19.22984984 18.55647575 18.00616692 18.32648919 16.20917324\n",
      " 15.94048355 40.44304575 24.93995665 24.55706495 26.17126032 47.56299085\n",
      " 48.57509584 48.92296041 21.89045992 23.47663172 48.88830552 21.21745586\n",
      " 22.24469801 22.12855254 21.21745586 21.21745586 20.71319839 23.99651065\n",
      " 22.20628325 27.61661251 22.24779919 24.35641132 28.82910017 37.4336891\n",
      " 41.82612485 31.40530134 37.2617559  31.63960058 24.06803666 27.95722996\n",
      " 48.31846952 28.85327104 30.14916251 34.44402572 32.43461899 29.21282212\n",
      " 34.58982726 29.81477151 29.09606486 48.42621104 33.91839935 30.81677594\n",
      " 32.76161643 33.0058017  33.0058017  23.35364085 43.33574902 48.15111119\n",
      " 48.42621104 23.7319089  23.12852809 20.08360727 22.292716   18.3152002\n",
      " 20.15144641 18.32878493 21.24073814 25.61968555 20.32169665 23.99488849\n",
      " 22.29871705 25.40375278 20.33285354 23.37310689 27.79745637 20.83190671\n",
      " 26.36215877 26.63632325 45.15579507 45.69665731 43.92509937 30.92171422\n",
      " 45.71273114 31.55492563 22.4680608  32.11251767 44.32137075 45.54983148\n",
      " 27.42782572 22.9617272  25.92533441 32.46382356 23.75605744 25.56397894\n",
      " 24.60210386 20.62465265 21.53758885 25.22345796 19.06214513 17.84017293\n",
      " 21.69626278 20.93442255 22.86047593 26.53529504 23.71037189 26.40330856\n",
      " 32.45002858 40.12441971 21.62770163 20.16906432 43.22019612 48.96580343\n",
      " 36.19046627 31.35388466 34.9431359  44.12722649 46.8156711  32.19902229\n",
      " 34.9431359  22.86211519 29.53873565 47.98290935 46.00178483 21.93765745\n",
      " 21.54793337 25.23142491 24.33883673 35.61319402 31.31696508 32.04267127\n",
      " 33.35308931 31.2559175  25.95200717 34.35510039 46.48696004 35.2163881\n",
      " 45.64080794 49.0327787  30.55331866 22.33257136 21.69757503 23.53652066\n",
      " 23.08245711 24.79937913 31.21276685 34.29118996 28.11258611 23.85939846\n",
      " 21.98861298 27.07522156 25.03558428 19.24341933 24.20354062 30.25026064\n",
      " 26.3510736  24.97967893 24.33108926 32.31816475 34.95139768 27.72254529\n",
      " 34.27356754 28.58064288 26.28401898 20.25949225 19.15765455 23.40595016\n",
      " 19.9069318  22.22895448 23.43789368 19.7967241  17.99129269 18.86799165\n",
      " 21.90295702 21.44864267 23.74221793 23.74221793 21.77357441 19.88044313\n",
      " 23.74861493 26.188891   24.33547333 21.31173366 20.3949194  23.03935223\n",
      " 22.0186464  19.24261422 19.64398129 21.95831249 21.85754325 20.6350395\n",
      " 20.01568444 19.85894712 20.79851822 20.16200017 20.51536951 31.99762077\n",
      " 20.68060523 25.59062004 30.87902463 19.41753345 18.59475908 23.18796837\n",
      " 25.72871802 28.3234078  22.31812575 24.88336613 21.31087817 31.0527335\n",
      " 19.34403778 20.75173519 15.87445808 20.5265433  20.70117246 20.5265433\n",
      " 23.32606114 19.68233643 20.00496907 17.88381107 28.83843559 24.00526687\n",
      " 19.09817287 21.32938439 50.07163944 48.82160629 48.20203737 47.2777543\n",
      " 46.84319485 14.36205747 13.53142624 17.48924424 11.79294408 12.03751809\n",
      " 10.7690999  11.77270178 13.30284038 10.53147486 11.61391857 11.4278251\n",
      "  9.02188405  8.92022632  9.50462006  8.55668465  9.66190862 11.96240478\n",
      " 14.65412353 17.1613234  10.55147356 14.45336107 12.65116497 14.27056086\n",
      " 13.89813053 11.94012717  7.77595912  9.18480867  8.37379402 10.28701903\n",
      " 11.98974767  9.49769797  7.70573926  7.36799143 13.36327035 26.14624567\n",
      " 15.17003545 20.94325541 16.51890218 16.88756044 14.57744105 14.89023868\n",
      "  8.24976464  8.63264333  9.50804859  8.93571718  7.75831071  9.03788871\n",
      " 15.02396264 15.06486095 19.58003642 12.86473687 13.39712744  8.56134775\n",
      " 13.56904967 10.98178079 10.67788405 10.28130892 14.4042725  15.46887706\n",
      " 17.90238886 15.34185827 12.90173312 11.40186526 10.99905848  9.72482922\n",
      "  9.45412739 11.70236191  9.99097952 13.44394369 16.75333771 14.22574262\n",
      " 10.75976886 10.18568291 16.33703165 14.63372832 15.14455645 15.09377379\n",
      " 14.00999287 16.72939436 17.1613234  16.21455097 12.35874932 14.39549294\n",
      " 14.28247556 12.85554461 15.09377379 18.58227987 16.47031642 18.94780328\n",
      " 19.79664167 20.4529397  21.22275643 20.45709742 15.75204166 16.60776586\n",
      " 17.55418796 19.39206231 18.10615643 20.45030404 20.66821931 28.06922267\n",
      " 16.67357885 16.26120202 17.72975505 13.19839222 17.20168726 20.15508873\n",
      " 20.90931887 24.17717967 27.62733557 20.78673312 20.75924242 21.3133487\n",
      " 18.99382477 20.93387158 15.10676681 11.06340755 10.26917289 15.17721649\n",
      " 17.95736363 21.10085132 21.34700608 21.00568378 17.69219141 20.52223098\n",
      " 20.76838574 18.76022157 20.23462213 22.18273078 19.05073131 26.01075867\n",
      " 22.94032743 16.83667178]\n",
      "<flaml.model.LGBMEstimator object at 0x0000024DFA84A850>\n"
     ]
    }
   ],
   "source": [
    "#Prediction with the best model\n",
    "print(automl.predict(X_train))\n",
    "print(automl.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullraw = pd.read_csv('C:/Users/shikh/Desktop/shikha documents/ARIMA-And-Seasonal-ARIMA-master/perrin-freres-monthly-champagne-.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing null values\n",
    "fullraw.drop(105,inplace = True)\n",
    "fullraw.drop(106,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Perrin Freres monthly champagne sales millions ?64-?72</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1971-12</td>\n",
       "      <td>12670.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1972-01</td>\n",
       "      <td>4348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1972-02</td>\n",
       "      <td>3564.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1972-03</td>\n",
       "      <td>4577.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1972-04</td>\n",
       "      <td>4788.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1972-05</td>\n",
       "      <td>4618.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1972-06</td>\n",
       "      <td>5312.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1972-07</td>\n",
       "      <td>4298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1972-08</td>\n",
       "      <td>1413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1972-09</td>\n",
       "      <td>5877.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Month  Perrin Freres monthly champagne sales millions ?64-?72\n",
       "95   1971-12                                            12670.0     \n",
       "96   1972-01                                             4348.0     \n",
       "97   1972-02                                             3564.0     \n",
       "98   1972-03                                             4577.0     \n",
       "99   1972-04                                             4788.0     \n",
       "100  1972-05                                             4618.0     \n",
       "101  1972-06                                             5312.0     \n",
       "102  1972-07                                             4298.0     \n",
       "103  1972-08                                             1413.0     \n",
       "104  1972-09                                             5877.0     "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullraw.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing column names\n",
    "fullraw.columns = ['Month','Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting month column data type to datetime \n",
    "fullraw['Month'] = fullraw[\"Month\"].values.astype('datetime64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1964-01-01</td>\n",
       "      <td>2815.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1964-02-01</td>\n",
       "      <td>2672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1964-03-01</td>\n",
       "      <td>2755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1964-04-01</td>\n",
       "      <td>2721.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1964-05-01</td>\n",
       "      <td>2946.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Month   Sales\n",
       "0 1964-01-01  2815.0\n",
       "1 1964-02-01  2672.0\n",
       "2 1964-03-01  2755.0\n",
       "3 1964-04-01  2721.0\n",
       "4 1964-05-01  2946.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullraw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = fullraw['Month'] \n",
    "y_train = fullraw['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML()\n",
    "automl_setting = {\n",
    "    \"time_budget\":10,\n",
    "    \"period\":12,\n",
    "    \"task\":'forecast'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   1964-01-01\n",
       "1   1964-02-01\n",
       "2   1964-03-01\n",
       "3   1964-04-01\n",
       "4   1964-05-01\n",
       "Name: Month, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2815.0\n",
       "1    2672.0\n",
       "2    2755.0\n",
       "3    2721.0\n",
       "4    2946.0\n",
       "Name: Sales, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 10-12 13:44:54] {1432} INFO - Evaluation method: cv\n",
      "[flaml.automl: 10-12 13:44:54] {1478} INFO - Minimizing error metric: mape\n",
      "[flaml.automl: 10-12 13:44:54] {1515} INFO - List of ML learners in AutoML Run: ['arima', 'sarimax']\n",
      "[flaml.automl: 10-12 13:44:54] {1748} INFO - iteration 0, current learner arima\n",
      "C:\\Users\\shikh\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\shikh\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\shikh\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "[flaml.automl: 10-12 13:44:55] {1865} INFO - Estimated sufficient time budget=9784s. Estimated necessary time budget=10s.\n",
      "[flaml.automl: 10-12 13:44:55] {1938} INFO -  at 1.0s,\testimator arima's best error=0.5604,\tbest estimator arima's best error=0.5604\n",
      "[flaml.automl: 10-12 13:44:55] {1748} INFO - iteration 1, current learner arima\n",
      "[flaml.automl: 10-12 13:44:56] {1938} INFO -  at 2.2s,\testimator arima's best error=0.4095,\tbest estimator arima's best error=0.4095\n",
      "[flaml.automl: 10-12 13:44:56] {1748} INFO - iteration 2, current learner sarimax\n",
      "[flaml.automl: 10-12 13:44:57] {1938} INFO -  at 3.0s,\testimator sarimax's best error=0.5604,\tbest estimator arima's best error=0.4095\n",
      "[flaml.automl: 10-12 13:44:57] {1748} INFO - iteration 3, current learner sarimax\n",
      "[flaml.automl: 10-12 13:44:58] {1938} INFO -  at 4.6s,\testimator sarimax's best error=0.3930,\tbest estimator sarimax's best error=0.3930\n",
      "[flaml.automl: 10-12 13:44:58] {1748} INFO - iteration 4, current learner arima\n",
      "[flaml.automl: 10-12 13:44:59] {1938} INFO -  at 5.2s,\testimator arima's best error=0.4095,\tbest estimator sarimax's best error=0.3930\n",
      "[flaml.automl: 10-12 13:44:59] {1748} INFO - iteration 5, current learner arima\n",
      "[flaml.automl: 10-12 13:45:01] {1938} INFO -  at 7.1s,\testimator arima's best error=0.4095,\tbest estimator sarimax's best error=0.3930\n",
      "[flaml.automl: 10-12 13:45:01] {1748} INFO - iteration 6, current learner arima\n",
      "[flaml.automl: 10-12 13:45:03] {1938} INFO -  at 8.8s,\testimator arima's best error=0.3932,\tbest estimator sarimax's best error=0.3930\n",
      "[flaml.automl: 10-12 13:45:03] {2043} INFO - selected model: <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000024DF6C6B970>\n",
      "[flaml.automl: 10-12 13:45:03] {2104} INFO - retrain sarimax for 0.4s\n",
      "[flaml.automl: 10-12 13:45:03] {2110} INFO - retrained model: <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000024DFDF8B550>\n",
      "[flaml.automl: 10-12 13:45:03] {1539} INFO - fit succeeded\n",
      "[flaml.automl: 10-12 13:45:03] {1540} INFO - Time taken to find the best model: 4.601580858230591\n"
     ]
    }
   ],
   "source": [
    "#training data\n",
    "automl.fit(X_train = X_train,y_train = y_train,**automl_setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1964-01-01       0.000000\n",
      "1964-02-01    4451.586086\n",
      "1964-03-01    4826.222580\n",
      "1964-04-01    5164.458120\n",
      "1964-05-01    4325.741953\n",
      "                 ...     \n",
      "1972-05-01    5867.651770\n",
      "1972-06-01    4621.709630\n",
      "1972-07-01    6048.544895\n",
      "1972-08-01    4276.373424\n",
      "1972-09-01    3791.792828\n",
      "Freq: MS, Name: predicted_mean, Length: 105, dtype: float64\n",
      "<flaml.model.SARIMAX object at 0x0000024DFDB25DF0>\n"
     ]
    }
   ],
   "source": [
    "#Prediction with the best model\n",
    "report=(automl.predict(X_train))\n",
    "print(report)\n",
    "print(automl.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24dfdfb0610>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD4CAYAAAAQP7oXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAB08ElEQVR4nO2deZhkVX3+P6fW3vdlerpnp2eYhX3YF0VWBQV3MEZMVKISo9GfW0yMxmBI1JhogopLFKMCIS6AAhJQFGQbEJgZZme27umZ6X2pfTm/P845t25VV08v0123mTnv8/RT1afqVn3r1q3znve7HSGlxMLCwsLCYirweW2AhYWFhcUrB5Y0LCwsLCymDEsaFhYWFhZThiUNCwsLC4spw5KGhYWFhcWUEfDagJmiqalJLl261GszLCwsLF5RePbZZ/uklM0zPf4VSxpLly5lw4YNXpthYWFh8YqCEGLv0Rxv3VMWFhYWFlOGJQ0LCwsLiynDkoaFhYWFxZRhScPCwsLCYsqYlDSEEN8TQhwWQmwq8tj/E0JIIUSTa+zTQoidQohtQogrXONnCCE26se+JoQQejwshLhTjz8lhFg6S5/NwsLCwmKWMRWl8X3gysJBIcQi4DJgn2tsDXAdsFYfc6sQwq8f/gZwI9Cp/8xrvgcYlFKeAHwV+OeZfBALCwsLi7nHpKQhpfwdMFDkoa8CnwDcbXKvAe6QUiaklLuBncBZQog2oEZK+YRUbXVvB651HfMDff9u4BKjQiwsLCws5hdmFNMQQrwB6JZSvlDwUDuw3/V/lx5r1/cLx/OOkVKmgWGgcYL3vVEIsUEIsaG3t3cmpltYWBwFNh8Y5rl9g16bYeEhpk0aQogK4DPAZ4s9XGRMHmH8SMeMH5TyNinleinl+ubmGRc0WlhYzBD//MA2/uHel7w2w8JDzERprACWAS8IIfYAHcBzQogFKAWxyPXcDuCAHu8oMo77GCFEAKiluDvMwsLCYwxGkiTSWa/NsPAQ0yYNKeVGKWWLlHKplHIpatI/XUp5ELgHuE5nRC1DBbyfllL2AKNCiHN0vOJdwC/0S94D3KDvvwV4RNrtBC0s5iVG4inSGUsaxzOmknL7E+AJYJUQoksI8Z6Jniul3AzcBbwEPADcJKXM6Ic/AHwHFRzfBdyvx78LNAohdgIfBT41w89iYWExxxiOpchk7ZrueMakDQullNdP8vjSgv9vBm4u8rwNwLoi43HgrZPZYWFh4S2yWclILEV12Su2z6nFLMBWhFtYWEwJkWSarIR0xiqN4xmWNCwsLKaE4VgKgJQljeMaljQsLCymBEMa6awNhB/PsKRhYWExJYzE0gBkrNI4rmFJw8LCYkpw3FNWaRzXsKRhYWExJYwY95RVGsc1LGlYWFhMCSNxE9OQzIf6280Hhvn15oNem3HcwZKGhYXFlGDcU8C8KPD79u9e5vO2D1bJYUnDwsJiSnCTRnoekMZwLGX7YHkASxoWFhZTgps0UvOg/9RIPD0v7DjeYEnDwsJiShhxK415EAwfiaUsaXgASxoWFhZTwnxzT43ELWl4AUsaFhYWU0I+aXg/WY/E0qQy8yOT6/Gdffz9LzZ5bUZJYEnDwsJiShiJpwn51ZThtXsqmc4SS6ldF+ZDL6xfbz7Ij57a57UZJYElDQsLiylhOJaioTIEeB8IH43Pr6D8UCxFOivJzgO33VzDkoaFhcWkiKcyJNNZGqsUaXgd0xiJp53784E0BqOKxJLzwJa5hiUNCwuLSWEypxqrwoD37qmRvPRf71f3w9EkYEnDwsLCAsgFwRsrjdLwdnIcmWfuKaM0UsdBsaElDQsLi0lhSCMX0/Baacwv99SQVRo5CCG+J4Q4LITY5Br7khBiqxDiRSHEz4QQda7HPi2E2CmE2CaEuMI1foYQYqN+7GtCCKHHw0KIO/X4U0KIpbP7ES0sLI4WZmXvxDQ8nhznU3V6OpN1YiyptPeusrnGVJTG94ErC8YeAtZJKU8GtgOfBhBCrAGuA9bqY24VQvj1Md8AbgQ69Z95zfcAg1LKE4CvAv880w9jYWExNyh0T3ndsNDtnkp6PFG7g/LJTMZDS0qDSUlDSvk7YKBg7NdSSnOmngQ69P1rgDuklAkp5W5gJ3CWEKINqJFSPiFVJc7twLWuY36g798NXGJUiIWFxfzAcNSQhgqEp7wmjXmkNAa1awq8J7BSYDZiGn8O3K/vtwP7XY916bF2fb9wPO8YTUTDQGOxNxJC3CiE2CCE2NDb2zsLpltYWEwFwzqGUF85P9xT8ykQPhR1qR4b0zgyhBCfAdLAj8xQkafJI4wf6Zjxg1LeJqVcL6Vc39zcPF1zLSwsZoiReIrKkJ+yoJoy5lMg3OuJesilNLwmsFJgxqQhhLgBuBr4E5lr/tIFLHI9rQM4oMc7ioznHSOECAC1FLjDLCwsvMVwLEVteZCgbiMyn2IaXhNYntKwKbfFIYS4Evgk8AYpZdT10D3AdTojahkq4P20lLIHGBVCnKPjFe8CfuE65gZ9/y3AI3I+dCCzsLBwMBxLUVMeJOBTjgHP6zRiKWrKAsoWr5VG7PhyTwUme4IQ4ifAq4EmIUQX8PeobKkw8JCOWT8ppXy/lHKzEOIu4CWU2+omKaVJJ/gAKhOrHBUDMXGQ7wI/FELsRCmM62bno1lYWMwWRjRpGKXh9ep+JJ6mqTo8LzZiynNPHQdKY1LSkFJeX2T4u0d4/s3AzUXGNwDriozHgbdOZoeFhYV3GI6lWNRQgd8oDa8D4bEUSxsrebk3QnI+uaeOA6VhK8ItLCwmhXIHBQn4FWl4nnIbTzmFhl6v7gejSYdMvVY9pYAlDQsLi0kxEk+rQLhPB8I9nBwT6QzxVK7jrtcT9XAsRZO2xQbCLSwsjnukM1nGEoo0jNLwsjW6Sbd1Cg3nQXFfS3UZgOeuslLAkoaFxTzHd37/Mnc/2zX5E+cIpk1GTXmAgM/7QHhhHyyvJ+qhaIqWakVgVmlYWFh4ju89tpt7Xjgw+RPnCKZlR57S8HB17+ztMU+UxlA0RUvN/LClFLCkYWExjxFPZegZiZNMe9cIb9hNGr554J7Symc+dNxNaddds3FPWaVhYWHhJboGo0gJCQ8nIzdpCCEI+ISnxX0jBXt7eOmeMum2TVUhfMIqDQsLC4+xt181XPByBWtiCDXlQQD8PuHpdq/GntryICG/z9OJejimCvvqKkIE/T6rNCwsLLzFnnlAGm6lARD0+7wNhOvsqZqyIEG/8LROwyiNuvIgoYDPFvdZWFh4i339EWD+uKcAAn5Bxkv3VDxF0C8oC/oIBrxVGmZv8LoK71VPqWBJw8JiHmPvwPxQGiG/j3BATRcBn8/TinBTnS6EUC4hT2Mayj1Vb91TFhYW8wH7jHvK0xTXNDXlAcyGmgGf8DblNp524itBn/B0dW/cU7UVyj3ldSPHUsCShoVFESTTWbIe91fKZCX7BxVpJFLepdxGEmmqy4LO/wG/x4FwV1t0r91TQzHVd6o6HCDoF1ZpWFgcj5BS8qov/YYfPbXXUzsODMVIZST1FUFPlcZYIk1VONcQO+j32D0VT+WUht/nKYENRlPU6VTkUMBvA+EWFscjRmJpeobj7B+MeWrHPh3P6GytJpWRnimfsXiayrDf+T/g8zYQPqxjGoCOaXhoSzRFXYWyJWSVhoXF8Ym+SALwvrrX1GisbK0CvItrKKWRc0/5fcLzlNuacqV8Qn5vYxqD0SR1FarIMOSxq6xUsKRhYVGA/jGVEZPwsHUHwN7+CCG/j8UNFdoe70ijuizfPeVtIDxfaXgdCK+vcKkeqzQsLI4/9I8ppZFIea80FjWUUx5UriGvJqSxRIF7yi886z0VT2VIprN5MY1U2tuU29pyqzQsLI5r9BnS8HgC2DsQZUljJSFdH+GV8il0TwV93gWfC1uaBD2uwh6K5SsNL4swSwVLGhYWBegz7ikPlYaUkr39ERY3VBAOeKc0Emm1sq8apzS8OTe5FiI65dbDOo1EOkM0mckFwq3SUBBCfE8IcVgIsck11iCEeEgIsUPf1rse+7QQYqcQYpsQ4grX+BlCiI36sa8JXSkkhAgLIe7U408JIZbO8me0sJgW+k0g3MMJoG8sSTSZYUljhaM0vLAnklDqxp1y62UgfJzS8DCmMewU9mn3lMeZXKXCVJTG94ErC8Y+BTwspewEHtb/I4RYA1wHrNXH3CqEMEuUbwA3Ap36z7zme4BBKeUJwFeBf57ph7GwmA04gXAPC+r2DaieU0sbK532HV4on0hCreyrXMV9Qb/PQ6WhSaMs557yisCGtC0595TwNL5SKkxKGlLK3wEDBcPXAD/Q938AXOsav0NKmZBS7gZ2AmcJIdqAGinlE1JKCdxecIx5rbuBS4wKsbDwAk5Mw0P/tEm3Xeyx0hjVGx5VFdRpeBfTUPbU6pTboIcpt4MR3RbdBsKnhFYpZQ+Avm3R4+3AftfzuvRYu75fOJ53jJQyDQwDjcXeVAhxoxBigxBiQ29v7wxNt7A4MozS8DJ9ck9/FCGgo76ckN/nmT1jRmmEC5WGR6RRoDS87CxrlEadTbk9KhRTCPII40c6ZvyglLdJKddLKdc3NzfP0EQLiyMjpzQ8dE/1R1hYW0444CesU269sCfnnsqPaXhVp1E8puGReypqNmDKBcJtTGNiHNIuJ/TtYT3eBSxyPa8DOKDHO4qM5x0jhAgAtYx3h1lYlATJdNZxgXjpnuobS9JaEwbwVGmMJoq4p/weBsJjaYJ+4cR5VJ2GR+4pZy+N/EC48sAfu5gpadwD3KDv3wD8wjV+nc6IWoYKeD+tXVijQohzdLziXQXHmNd6C/CIPNbPusW8hcmc8glv3VOF7SnAGxIbixdxT/k8DITHc3tpAAQDwrPV/VBUbQZVGVKEGvL7kFJ1Jz6WEZjsCUKInwCvBpqEEF3A3wO3AHcJId4D7APeCiCl3CyEuAt4CUgDN0kpjab+ACoTqxy4X/8BfBf4oRBiJ0phXDcrn8zCYgYw8YwFNWVEkt65p4aiKVYtqAbIZU95EtNQq2m3e0rt3OddTMO4pkARmGcxDU3sOQLLJSwE/MduCdykpCGlvH6Chy6Z4Pk3AzcXGd8ArCsyHkeTjoWF1zDxjIV15Ww6MOyZHcOxlJOVY0jDm0C4Is6KYH72lHd1GmmnsA+UeyqrV/d+X2mTLgejSSfdFnJuxFRaQqikppQUxy4dWljMAEZpLKwrJ5n2xj+dymQZS6TzAqzgEWnE1V4aPteEHPCwYeFovEBpBJRdXqiNoWjKcSEqW7QizHjb6HKuYUnDwsIFt9LISjxJLTVbiJpVrGkj4pV7yl0NDjoQ7qF7yt1x11nde0Ua5W6lYQjs2I5pWNKwsHChP5IkHPDRUKkmAy8m6uGYUju1BYFwL5RGJJHJ63ALKo7gWUwjnnZqNEC5p8CbiVq5p3JKw8vvqZSwpGExb7C7L+L5D65vLEFTVdjTJoFGaZhVrN8n8PsESQ/cHqOJdF4LEWNPJis9cd2Nc095pDSklEppVHpvS6lhScNiXmAomuTyrz7Kz5/v9tSOvrEkjVUhV8ZS6SfqXP5/bkIKB3ye9J4ai6eoLnBPBT1ywyTSGeKpbJ49xpZSk3sslSGZyTrJCuBtPU0pYUnDYl5gb3+UVEZyeCTuqR39RmkEvWsSaCqNC10fXnW5LXRPmXTSUtdqmD5YbqVhXEKlXt0PFsSdID/l9liGJQ2LeYGuwRiQq0D2Cv1jSRorQ4T82j3lwQQwHDMtt/PTOb3qPeUu7AOVcgulTxJw+k6Vu2pGfN7ENJxmhS5iDzspt5Y0LCzmHF2DqqurqUD2AlJK+iMJGqvCnrYjH4qm8PtEnhsmHPRmV7jReH62ErhI4/o/gZtuKqEtZgMmdxzBm5Tb4djxqzQmLe6zsCgFuoeU0hjzUGmMxNKkMpKmqpCnW6wORpPUludaZYA3SkNKSSRZxD01oooe0w/9H6xeUTJ7TLPC6jLvJ+rB6Hil4WX6bylhlYbFvIBxT3mpNPp036kml9LwJHsqlsoLggOEAv6SK414KksmK/PdU5s2EbzlnwBIndAJ8dLFoJytXsvH12mUen+PojENGwi3sCgdjHvKy5iGqQZvrAq52pF7ENMoKBoDnT1VYtUzWqTvFH/zNwQSiigyp5xaUtIYjefvpQHepbkOR00tzfigfNIW91lYzC2klPNCafTravDGyrCzgvWCNNwdbg1CgdK7p3L7g7vcUwcPEli6BIBUWTnEYiWzJ+eeKpJy60H2VEXI79TzgE25tbAoGYaiKaK6o2wk6aF7SpNGU3Uol3LrQUxD9TQarzRKPTEWa4vO4CCBygoA0uGykrunfAIqQ/kNCwFSj/0BvvzlktlSWA0O3vbBKiUsaVh4DqMymqvD3sY0tHuqoSLkaTtyd4dbAy+K+xz3lLu4b2CAQJUijVS4vOTuqeqyYF7zRKdO479/DF//eslsKUbsVmlYWJQIJp5x4oJqb2MakQT1FUECfp9nfYSS6fwOtwZeFPfl3FOaNLJZGBoiWFUJQDoUVu6pErUTGYmn84LgkEv/TR3uLamrbKio0rDZUxYWJYFJtz1xQTXJdNazvbn7x5I0VqktVr3qLGvy/4utYktNYOM2YBoZgWwWvyaNTDisiCRdGqIfiaWoLig0dDKW/AGIRktiByilUTuB0vBym+BSwJLGcYxsVvLDJ/cS8bgKu2swRnU4wMK6ciC3wi01VLPC/I2PSk1gpsNtYSA8HPCX3JZcTEOTxuAgAMEataNgKqgItlQr/JF4apzScNqR+zRplEj1FG7ApGyxSsPiGMfG7mH+7uebeGTrYU/t6BqM0l5f7hRteRXXUC1E1ETolX+6sMOtgRfZU2OF7qmBAQACNVWADoRDyeIaowVt0QGC27YCkGpuUYSRTM65HdmsZDiWyndP3XEHvlddpHc1tKRhcYxi74CS81EPM5ZAKY2O+gpncjIB2FJjIJqkoVJNBD6fIOQvfeuOYh1uQWdPeeCe8vsEZTqTzCiNQG0NAKmgnjRLRBpqA6YC0rjnFwCk15+pBkrgohqNp8lKqHUT+2OPwWOPEcykbSD8SBBC/LUQYrMQYpMQ4idCiDIhRIMQ4iEhxA59W+96/qeFEDuFENuEEFe4xs8QQmzUj31NuPsnWMwZ9mvSiCW9255SSkn3YIyO+nKHNLxwT5nVo9ftyE2H28LsqVCg9ARmtnp1fo5GaWjSyBjSKJl7qiAQLiXBn94NQLK+QY2VgDQGi3QhNoQaikdJ7fe2vf9cY8akIYRoB/4KWC+lXAf4geuATwEPSyk7gYf1/wgh1ujH1wJXArcKIUxlzDeAG4FO/XflTO2ymDr29kcAiKa8I42RWJrRRFqRhg64jnmgNEbiKaQs6CUU8JV84yMnEF453j2VzkqyJewsO5bI5KfbGqVRVwtAuoRKI5OVjCUK3FObNhHcugWAVEDbUkrSqMyvX2HNGoJIEr/5bUmD8qXG0bqnAkC5ECIAVAAHgGuAH+jHfwBcq+9fA9whpUxIKXcDO4GzhBBtQI2U8gmptgK73XWMxRxin1YacQ+Vxn6dbutWGqMexDQK9+UGb5TGYDQ5rsMtjz1G+GAPUNrK53H7g2ulEayvA1wTdQlIY6zIXhrcfTd+AX4BKb8eL4HqGXIy3AqURns74fpaUmMR+Oxn59wOrzBj0pBSdgNfBvYBPcCwlPLXQKuUskc/pwdo0Ye0A/tdL9Glx9r1/cLxcRBC3CiE2CCE2NDb2ztT0y009g+oH1jMQ6Vh0m3b6yqc9hBedLrNdS11kUaw9E0Ch6KpcR1u+eAHCX3nNqC0rdrHEun8vlODg1BWRqBCZbmlA6WbqIu1EGHzZli5koDfR8qvx0uwws+5EAuURn09wcpykss74VvfmnM7vMLRuKfqUephGbAQqBRCvPNIhxQZk0cYHz8o5W1SyvVSyvXNzc3TNdnChWQ6y4Fh70nDVIO7lYYX2VNO1lJBq+uSZ08V6XBLTw+hYeUaSpTQXTaWyFBZqDTq63P7aRjSKIHSMG67PPfUoUPQ2qq+J6M0SuGeihhVWqA06usJ+n2kqmtgbAw82NO9FDga99SlwG4pZa+UMgX8FDgPOKRdTuhbk8/ZBSxyHd+Bcmd16fuF4xZziK7BqJPSHvXQPdU1GKUy5KeuIkhFyI8Q3iiNodj41aPa+KjEMY3CDrfpNPT3O113k8+9UDJbxu0PPjgIDQ0E/KUnjdxWry57NGkEAz5SPh0eLZF7SgiXq0xKhzRCAR9J47aLRObcFi9wNKSxDzhHCFGhs50uAbYA9wA36OfcAPxC378HuE4IERZCLEMFvJ/WLqxRIcQ5+nXe5TrGYo5g4hkAcS/dU4Mx2uvLEUIghKAqHPDGPVVk9ehNym1Bh9veXpCS8FWvAyDx958r2QpWbfVaTGnoPSyMS6iE7qk8pXH4sCINv1DFfVAy91RteRC/6YEVjUIq5SiNpDkvo6NzbosXOJqYxlPA3cBzwEb9WrcBtwCXCSF2AJfp/5FSbgbuAl4CHgBuklKaq/8DwHdQwfFdwP0ztctiajDptq01YU9Tbk2NhkFVOOCNe6pw9YhSGl4U9+UpjUOHAAgtXABA8qWt8N3vlsSWSKF7SisNZ4tVMzmWQGmMFLqn4nEYHoaWFuUSMkqjJNlTqfHxDMgpDd+xTRpHtd2rlPLvgb8vGE6gVEex598M3FxkfAOw7mhssZge9g1ECQd8LGmo9DimEeWMJU4pj2dKYyiapKbMtXpEte4wu8WVCqpWxKU0NGmE62uBGMnlJ8C998KNN86pHVmd4poXCB8YgFNPJWB2y/OVjjTGuacOa693ayuhYR8pode/pXBPFapBN2kM+YgaAhsbm3NbvICtCD9OsW8gyuKGCspDfs+URjyVYSSeprUm7IxVlXnknoqmivYSKmVMo2iHWz05hhpV8VqipVU1DpxjmH1NisY0TCDcX7o4gnFPOe4yF2kE/S7SKIl7quBaKVQapvzsGFUaljSOU+zt16QR9HumNAYiZntVF2mEAx7VaYzfLa/U7qmiHW6Ne6pZkUaysqY0pKGr8h33VCqlVs7u7KkSKo2RWJrKkN9ROea80NJCMCBI4YovzDHGxZ1cpBH0C1JmWrVKw+JYgZSS/QNRFjVUUBHyjjScnfJcpFHtkdIYt6lONqv35S4laRTpcHvoEITDhHVn2WRlVUlIY1xbdDMxNjQ4Lrw0AoQoDWnEU/mFfYY0WlsJ+Hwks4DfXyL3VMG1kqc0/DkCs0rDYjYwGk/xdz/f5Gk78oFIkkgyw+KGCspCfmJJbxqs9Y8ZpZGbJL0LhLs21ZESVq4k9OILJVUaRTvcmloEnXKbqKxWAeA5hlF71QUdbqmvRwihVtRZCWVlJZmoR+Op8ZlTAC0thPw+1Vm2omLOlUYqo1yIxfpOGaWRMFVmVmlYzAYe39nHD5/cy3P7Bj2zwaTbLmnU7imPutw6SqPS7Z4KekKoQ5FUrmtpNAq7dhF++kkSqdLZUrTDrSENs5NgRaVSGnO8b8Q495RLaQD4fYJMVkJ5abZ8HYml86vBDx2CykqorFTuqYwsCWkUazfD4KBSXDU1isCkVRoWs4h9Tjty7zKWjA3umIYs0eY1bpg9uZuq3UrDz1gyXdLGfKlMllH36lGvqsOxCIkSEljRDreaNJxNocoqVXwhkZhTW8YK9wd3KQ2AoE+v7svKvHFP6RoNULv3lUppmO+otlBp1NWBz6ebXOpr1yoNi9mA0+/JS9LoN00CVfZUVpa2EZ5B/1iC8qCfilBuBVlVFkDK0nbeNQFop2upniBD5WWkhI9sV9dEh86JHXkdbguURqJM9X2a67iG454qEtMACPgF6Uwp3VNpagqVRh5paNUzx7YMTqQ0DJm6CcwqDYvZwHxRGi3VYcpDfsq1rzzuQVyjP5LMUxmg3FNQ2v5TzuqxPJ80wpe+BoDkzf9UEjvGdbjNZlVFeGsrYZ3emgyXhjSMi7ByAqUR8PtIZ7Olc08VC4S3qF6opYxpDE20l4Y+L0ppZKGqyioNi9mBaQXu5W55pkYDoDykJqNoCX33Bn1jCWd7VQMv9tTI+akL3FOLVUu0xA9/BC+/XBI78jrc9verliGtrYT17nnJkN5idY5JY8whDV1zYJRGXR0AAZ9LacwxaUgpGY0XxDTy3FOiZKRh0sRri3S4VbYo1SOrq63SsDh6ZLOSLu2e8lJp7B+IsrhRk4ZWGl64y/rGkjRV5SuNag/21BgXgDbuqZpKABII+NGP5tyOiVqImE6uAImQJtk5zqAaTaQJ+X2EA5o0BgagpgYC6vsJ+AXpEmVPRZMZMlmZy57KZKCvzyGNgN9HKp0tiXtq26FRyoI+FtaV5wZdpGFiT8nqWksaFkePw6MJJ3bgFWkk0hl6RuIsqs9XGl7UavSPJfJqNMCtNEpJGgUuB6M0dG1Eoq5BrfrnGAdH4rTWlOUGXFXPPp8g4BMkg/p8zbHSGIoUuIN0NbiBEwgv5p4aHVWutVmC06zQ2NPXp15fu6eCfh18LoHS2Nw9wpq2mrx2M/lKQ/flqq2z7imLo4e7s6x3aa5JpIS2WjU5OTGNEpNGNivpjyTzajQA1z7hpTs/w8WURjhMuEKdo0RdAwwNzbkdB4fjLKh1kYar6hnUKjZp2pHPMWl0D6nuww50h1uDvEC4mzRiMVi0CH7yk1mzxfT/ctxTLjIFCJXIPZXNSjYfGGZde21u0NUWXdlilYbFLMKQhhDeKY2+UZWqaVp3ODGNEtszHEuRycrxMQ1P3FNJAj6Rn17a0EBIu2aStfVz7g7KZiWHRiYgDTM5BnwkfKUjjY76AheMS2n4fToQXuieGhxU52rHjlmzZVxb9ILz4mQszbF7and/hEgyk08asRgkkzmlod1TqapqqzQsjh77B6IIAYvqKzwjjf6Iad2hVvhexTScwr7q4qRRSveU2S3PCUBr0jDB50RN3Zwrjb5IgnRWOgoQUJNjIJCfmWPakc8haWSzku7BGB11EyuNoIlpFLqnzMZDs3i+RgvdUwUKLBgoTfbUpm61cFiXcLkqXdXg4FIaVTVWaVgcPfYPRGmrKaO2POhZ9lTfqC6oK1AapY5pOIV9lfnuqUoPtnwd16zQkIbfRRpzrDQODquJd0FNAWm0tIDe9Cgc8JOUAkKhObWnb0zF3o6kNCbMnjKrazOZzgKMe6pmAveUk7FUPvekERKSzovPhu5uNVhIGiYQXmlTbi1mAfsHVZPA8pDfM6XRW9Ak0KuYhlE8jQWB8FDARzjgK20gPFKQtVSgNJJVNXOuNAxptNW6JmpXARto91Q6o7KY5lBp7Nf7tjsxDSmLxDRcFeFul9BESiORgP/3/2ZEJsY9Ve12TwWDTvpvyGw/W16uquXTc3PtbOoeYbUvRjCVhI0b1WABaQT1QiNVqVNuPei0MNewpFFC7JsnnWUrQ35HYRjSKDWJmdhKYcotqIDnaMndU0WUho5pJKpq5l5pjCjSaK11kWgBaYQDulV7be2ckkb3kCIBZ0dFs51podIo5p4yq+tC0nj2WfjKV+Chh/LHn35aTf4HD05oj6mjcTZgMgpMuxOdibpCpUjPRVxDSsmmA8OsS2mS2LJF3U7kniqvVBleJSh8LDUsaZQI8VSGQyMJFjdUUBkKqOygdFplmcxieuJk6B9L5sURvHJP9UeS+ATj9rAAFdcoZfaUck+NVxpO646KKkUac7hq7BmOE/CJvOaNxZVGds6VRpcuQG03MY2CanAwFeEu95Q5NxMpDTO5FiqNF19U53b79gntebl3jIW1ZbmaEVdhn7EFIFWuSWMOXFT7BqKMxtOsi+h4ytat6rZQaQQKCOwYjGtY0igRurTkX9RQntst75e/hHe8A558smR29BXURoQDPrUlQskD4UkaKkP5+e5SwlNPUXXoAGP33Q8PP1wSW/J2YovH1aTT0JAr1KqsUgVlZkKcAxwaVjUaPnM+pBw3OaqdBOeeNLoHY9RXBCfscAsQ9AnSxj0FuQaKEykNQzzm1sC8tgluF8H2Q2N0tlbnBgrJVLunkmFtyxyQxkYTBO/fqwYmURqJMq3SjsG4hiWNEmG/q7NsRcivGvIVXnglgGrdkVvdCyE82b2vkLxIpeDss+Gcc6g82M1o1gd/+MOc2xFPZYilMjnF45ogHfeUmQDmMK7RMxzPz5waGlKpnG73VNCv3FPFSOPnP581V0jXYEypDEMERZWGDoSXazVi3nsi0phIaZj/TXC7AJmsZFfvGCtbq3KDhw87mVPgck+Z78ntnvqLv4AHH8x/USnh619Xfb2miE3dIwT9gpUHdTsZt9IQQrkMgVBAF/eZxpJWaeRDCFEnhLhbCLFVCLFFCHGuEKJBCPGQEGKHvq13Pf/TQoidQohtQogrXONnCCE26se+Jpzcx2MHpufUovoKKkIBFUPYtk09WMILq9A9BSquUeqYRv9YIr+wb88eeOYZ+MhHqL74QsYqauDAgTm3Y9wWq2aCdLunzGQ0h3GNgyNxWmuLV4MbhPy+HGm4bdm2Dd74RrjjjlmxpXsoRsehvbBiBfT0FFUaAZ+PVNalNAxpGDU2MqLUmYF5jWkqjX0DURLpbE5pSDlOaTikYZo5GqWRycBttylCdWPXLvirv4If/nDCc1CITd3DrGytJtyviaa3V3UJGBxUhKEz3EKFjSUtaYzDvwMPSClPBE4BtgCfAh6WUnYCD+v/EUKsAa4D1gJXArcKYXZg5xvAjUCn/rvyKO2ad9jXHyUc8NFcHaYipFaM6W3aj1uiCyudyTIQTY5r3VHmgdLojxTYsW+fur3mGqoqyxirqMqlNc4hJmohkueeMhPAHCkNKSU9wzHaCtNtYVwgvGj2VE+Put25c1Zs6R6M0d5/QJ3/66/PrcgLlEbGxDQgt7p3u2PcxGbO6zSVxraD6rex0pDG8PA4BebEEQrdU+YcFS4+zP+7dhV9z0KYIPhJ7bXqc7S1qQe2bMmrBle2FCiNmbqnslm46SZ44YWZHT+HmDFpCCFqgIuA7wJIKZNSyiHgGuAH+mk/AK7V968B7pBSJqSUu4GdwFlCiDagRkr5hFQ7Ad3uOuaYgUm3FUJQYaqwd+1RD5Zgz2eAgahqIdJckLFUEfKXPOW2b7Sgw+3+/ep20SKqygKMhSpKQxqRgi1Wi5BGwnSWdU+Ce/ZAe/sRA7hTxUgsTTyVPWILEdDZU5ki2VNmwt29+6htGYgkiaUydPR3K3J69FH4x39UDxYojaLuKXfcx02yM3RP7TikSKOzpSr/ea7z4sQ0TDNHQ2Dm/QtJw5DsFDsXdw/FGIqmWGtI4/zz1QNbt44jDSd7ytgy0wXh7t1w661w990zO34OcTRKYznQC/yXEOKPQojvCCEqgVYpZQ+AvjXfbjuw33V8lx5r1/cLx8dBCHGjEGKDEGJD7zT8kfMB+wZi49qRx6L6h1YipWEK+wprI5zAfIkQS2aIJDP57ilDGh0dVIWDjPlDJXJP6d3yiiiNgN+HT5BrEuieBDduVPY999xR29Azoia5cTUaMC57ynFPJZO5mIP5LcwCaZh02/YDu+H1r4f3vEd9N36/2iNCw2lHXuiecq+si5HGNN1T2w+P0VFfngvKFzkvxj2VLlQa5v0NSRiY/6eoNHYeVp/pxPqQ+pynnqo+dzGlYUjDXDNTURojI+r7zHtTrRqNAtdIpDPcv7HHiZF6gaMhjQBwOvANKeVpQATtipoAxeIU8gjj4welvE1KuV5Kub65uXm69noGKSVdA1EW6WKpSr1TXTSoL/ISkUauhch491QpYxrGjuaqAqXR0gLhMNVlAZLCT6KvXwXI5xDOTmyV45UGqCrsRFATiltp9PWp28IJaQboMdXgY31w331qAjl0SPnJm5qc5+Wl3EJObUxEGsPD8OlPTyvry2T5dezdBgsXqoDxyScrl4wr1JjXGh1yq/s5UBorCzOnoHhMw0zUhjTM93XwYH58xXxne/bkjx88CJdcMk7hmkLT2oT+bM3NsGpVcaURKCAN92/7hhvgQx8a/yFPPx0+97mCD657dxWQxlA0xQd+9By/2+HdovloSKML6JJSPqX/vxtFIoe0ywl9e9j1/EWu4zuAA3q8o8j4MYOhaIrRRJpFBUojEixTE0OJ3FNOvyezwk8k4MYbKX/2GeIbnlNFVrOwcp7cDqN4CpTGInV5OJ1ug+VHLPqaDZjCMWdf7oEBtaquVhNVOOhqEuieBA1pzIIaOmRI42tfVqv79nZVv9PUpGzRCLuVBownjYMH8zOH7rsPbrkF/vd/p2xLt6kG7+tWpFFeDo88Avffn/e8gLs1OuQrDWOzmyBmkHKbymTZ1TtGp4zAn/4p/MM/5OxwuacCxj1lyL3QPWX23zAwpJFK5RPEI4+ov//7vzw7nF0Mo5oAGhrgxBOLKg3jnkqZbsRupfH44/DrX+d/yIEBpXieeCJ/3CiNvXuL2+LaIrnUmDFpSCkPAvuFEKv00CXAS8A9wA167AbgF/r+PcB1QoiwEGIZKuD9tHZhjQohztFZU+9yHXNMYE+/WqEY95SJacQqq2HZspK7p5zsqRdegG9/m4pUnFhVrVqZmfYIc4j+sSItRFyk4fSfCpXPuYtqKJokHPA5RG4K+8yqOuT3kaRIv6dZVhpCQMvLW2HtWnjVq9QKs7Mz73mhQtIw9rhdtXv25O6blO57752yLV2DUaqDQq2qFy5Ug42NsG5d3vMCvoJAuJs0FixQ94spjbGxnHqUUj0nGFS/gYJK7r39EVIZycqNT8J//7dajX/ve+o93QrMmag1aRS6pyD/Ourpyakmt4tq8+b8W41IQqmRylF9vhsaYPVqda77+goC4doW4ct9LoNDh9T7uV1RJoNy06a893RIo6srTw0Zj4CZQ7zA0WZPfQj4kRDiReBU4IvALcBlQogdwGX6f6SUm4G7UMTyAHCTlNKcjQ8A30EFx3cB+cuaVzj29quLeFmTqhJ1AuFLlqvVfalII5Ig5Pfl9qDWE175mWcQa9E/9BJsNtRvmhVOojRGw3MfDB+MJvP3ezakoREOapdQbW3+JGTOUyFpPPmkmvgLM6327YO77ipqw8HhOM1VYYLdXXDWWSr42dMzbrIP+f2ks5KMVkF5SiOsCdjtojK1BA8+mD9RbdkCH/5wvmtGo3soRntYe4cNaRRBwO/LNSyEfPdUh3YcmHNg9pyo1FXShkBGR5UNK1bkPocL2w+pVfrK3ZvhtNPU859+Wq3KA7mVds49VUAabpJ3k8bBg8rlBvnB8Jdeyr/VMKv7ihFX6vHq1epzpdPFA+Hpgn3CIxF1P5PJJyqTSNHXl++iM+6pVCpPhY3bu90DHBVpSCmf1zGGk6WU10opB6WU/VLKS6SUnfp2wPX8m6WUK6SUq6SU97vGN0gp1+nH/lJnUR0z2N0XUS3RHaWhvvDY4mXKDVIq99So2l7VKYPRE15ZTSWxtFSuskL3wRzANE10sqdGRtSfJg2z2U4pMqiG9vdQ53NNnoWkEfAr0qirK640CpXQ736nJp1nnskf//KX4e1vLxoY7RmJ01YTVpOZe3XvmowAVwNFvZ+DmzROO03dLySNWr0Z0KOP5sY/+1n42tdySsSFrsEYHegA+xFII+gXqk6jmHtqwQJ1LRnSiMWUK3T5cvV/YXzjxBPVbYGLavuhUYSAEzY+pWIIlZVw5pkqEJ1niyYNXyD3fpBP3G5y7+lR5BwI5E/ghiwKlUYyQ8jvIzTkincZm2Fcy3hA7STo3ifc/dnc590oDff7ptPqezTE5oprHAtKw2IK2NMfYWFtOWW6OWCFT3FiZOEi5WooldIYS+QX9mmZXl5Tpeo0GkqzrWn/WDKvaaI73RZce2pU1Mw9aWzaRl3XntxAAWk4rTsKlcZE7inzA3/xxfxx83+RWopDw3Faw0Ll5rcXTRx0bAHd1gTySWPdOrXqNyvndFqtYt/1LjV+331q/MCBXLFbgSvS1Gh0JPXrmnqEIvD7BFJCxqSWulNuq6sVyZrzZchhItJYpT3cBcHwHYfGWFxXTvnLO/Mn6QKYKuykaaDodk8ZJWTIPZlU13hHByxZkjtfiYT6bioqlNvJRe6RRJrKsD8/SWLlypyLy0UaQohcEaZbabhjc0YBgiINc7whjX37lMJ4zWvU/664RiT5ClcaFlPDnv4oS5sqnP/LD6gM42hrW/5qZI5R2EKEnh5oaaGiLEgslUE2NJREaYwjr0LSMEqjtW1uYxpS0u8vo67f9YMu6p7KTKw0hofzex2Zz+ImDSlz/xep6+gZjtEmtPvoCKt7p0LdNOYbGVFE09+vsomWLs0pjd271cRz+ulw6aXK1SUlfOc7ilB8vnGkMRJLM5pI0zGq/fRGRRSBk+ZaWBsxNqYmy7q68eRg3FCFhX4TkMa2Q6N0VqLsNs85gi2pdMFGTENDKtOpqSlH7mbybmtTJGZIY9s2dS6vvlr971IDkWRaeQcGBlScorJSkdGyZeoJBYrQSUeeSGm4SWP7drjgAnW+DGmYhcUll6hbt9JIWKVxXGBPX4SljZXO/xV7lCSONbWU1D3VP1ZQhX3gALS1URb0k5WQbGopCWn0RwrIq4A0TMxlpLltTpXG4Z5+djV0sG7v5tykMh2lYXz0brVRTGl0d+cmyIJtUCOJNCPxNAtSekV6BNIIFyONwUHlJ29uVpOYIQ0z6a1erSbC3buVTd/6FlxxhRovII2uId3dtv/AEe0AFQgHV22EW2lUVhZXGoY0Cms2DCG4JtZkOsuevggr0yP5zykCh8CMu8wd06irU5/FLD7Md9XWpuwx7injmnrrW/P/R31HVeHAuCQJVq9Wt67rBVwJC8WUxrp1ue8mk1HXw6pVKg62eTP7+qOMbdOkcfrp6rpzkYajNF6J2VMWU8NgJMlwLOUEwQHKt6uVRrSusWTuKSkl/ZEi7qm2ttyWr00tJXNPjcuc8vmciapeE0p/44I5JY3f/nEPABfvegb++Ee1Mh8ZKVAaukmgW2lkMmoCMRlFbtIwBPjSS7ksITeBFCgNs49GW0RPpEdyT5kaAH9ArXiHh3PB40LSMKvZVatyq+cPfEBNnh/8IJx00riMHadG48DLk5OGmahN8DkeVyv1aDSnNAxpGHKYSGm0t6tjXEpjd1+EdFayckhP9itXTmiLU1CXkUppuGMatbWKIIqRxvLlypahIfV9+Xzw2teqTDlXXCOazFBh3FNugjAus3FKw1dcaQgBF16ovhspFRkkEg5pxLdu56qv/55/3SvU52hrUy40l3vKiWmErdKYX4hEZm31v1un27qVhn/7NsrSCaK+oLqwEonxFaGzjOFYilRG5isNQxomBbi+qXTuqcLMqbY2JyMm6PdRXxGkr6ZpTt1Tj+zoZ8FoH2sO71akYSa5vEB4EaUxOKh+9CedpP43E1E0qkh37Vr1fZogpyGN008fRxqmRqN16LCatFz1B4VwlEZa5vpPuUlj+XJFJIODamJasEBN3u3t6r2feAIWL4arrlK279mTt2A5YKrBTWHfEWCURkr4VF1GLJZb4U+kNIw7p9Bt1dCgPrdLaZgq7M59W1X8oTL3+ymECT4XdU8ZpWG+o0KlAcpFtXkznHCCep8TT8wjjTGjNPr780nDKLaC2E+e0jDn9+BB5SZbt06pjwMHctfCypWwdi1PVC9iNJ7m2WRY2SKE+r7cSiORJuATTnzLC1jSKEQ6DRdfDK973ay83F5DGq6YBtu2USEzap9wkz45x2qjrzDNNZNRP9K2tlzdSEPTnCuNRDpD31iSVndzPle6rUFzdZjecp35MwfnJpnO8vvDKS7e9QzC71ekUVANDq4tVuvqcjvYmXNkSMMQm1EZZmVvyOLFF9WP/6yzxrmnTDV42+F9apIPTOx2MK3a8/pPFSoNUGpjy5ac+wRU0SDAjTeqSd7Y7lIbg5EkQkDdnl1HDIJDrqAu4969z7hiqqrU6ruQNFq0O9ZNGqY9SWtrntIwXQNatm86omsKXDGNzATuqba2XFW4qdFoackF5l9+WSmNNWvU/2vX5rmnoomM+o0UKo3LLlPPK4j9hPy6R1h1de6cmM685jvZsiW3qNBK46ETzlYPhRtInaBrdApII5pUtnjZCNySRiFuvVWlSz7xxKyojd19UXyudFtAkYZPKqlpCrXmnDQKWoj09ip3go5pAMRq6tVFPoeqp2dITZLOrnBQlDSaqsL0BfU5mwMX1dO7B4hkBZfsfAbOO29C0sjbYhXURGSC4KtWKTeRWb2aH/ell6pxN2mcfLIq1uvvzyNm455a0DW5S8hxT7n31JiINLZuzc84+rM/g2uvVftLQM615oprjMTTVIf8+NKpSW0J+lwTtdm9z0yQhUpjYEBN1DU1ikzc7qn6+twk7iKN0bjy3Vdv2Tg90ijmnlq4MFcVrpM/CARypLF1qyJzQxpr1uRlUI0l0ipbqZA0jmBPMl3gnjp4UC0KzHeydasijdpaaGlBrl3LIyecSaXIkvQH2dF5inrekiXqPOnXiRhbPIQlDTe6u+Fv/1ZNYNnsrGwCtKcvwsK68txWlQMD0Nen9tRIZEqoNApIwyXTnZhGrfbNzuGmUE5DPN2HCyknVhpSt2KYAxfVI1sPEyLLeftfVCvGl1/OxQMmqtOAfNJoblarWHMujdJYsUJNPC++qFyPW7cq0jB+eZfa6B1NUF0WoKx7/5RJI689uiGNpqYcaTz5JAwNkT5xNQ+9dEjtsLdkCfzsZ7lK6iVL1Ao/jzRS1Jj5aNKYhg6EmwK/WCzXd8rENCIRpcwMOfh86ty6lYaJBxS4p0ZiKUJ+QdlA3xRIw1UbYdxTptrcuKdAXUc9PXQtW835tzzCZx7ey2hbBzzwgCKVtWvV88ytDlhHk2kVeJ4iaYQCOqZRVaW+f1Og19qqiKOmRl0T27c7qbub02UcrG7i3T0bANjYoglt8WJ1qxckRml4CUsabnz4w+oL/uUv1Urkd7876pfc2x/JC4KbAGV5eUjt3lcq0hgt6DvlJg3jnqrSqmcOXVSmt1FHnVYRAwNqwimmNEyvwjlQGo9sPcS5qT4qaqtVwRiovkMwPqaRyuSUxtBQjjSamvKDrPv3q1Vze7siiRdfVBNPJpNPGq64xkg8RW15UH3GIwTBjS1A/kZMvb3qfjisJsi6OvjVrwC4r76T992+ga89UmSfDZ9PqQ03acTS1KALHSchDbNNr5OxVExpmPPlJodiSgPUhGrUL0r11Ji5cRLSEELk0lwNaYyNqdcy7ilwSOPzp76J3tEEP3l6H5e/7Z955JC+0NzuKXDiGpFEhsoAigSnpDREzj0FyhajNITI9a3ats35bA9tOYyQknf/7D+pTkTYWKbJvYA0IkmrNOYPfvlL1djtb/9W+XvXrz9q0pBSsrsvwpJGl2tqg1pJVNRVE0umxzefmyP0R5L4hKsFuCGNhQtzSqNCX+RzGAzvGoohBLm9IwrSbQ2aq8NE01I1dZxl0ni5d4w9/VEuGdihJitTTW0a1RW6pzITKI2mpvwg6z4dlwiF4JRTlN2/+Y167OSTlRLw+/OUxkgsRY3JzJmpe8rd8XnZMscf/3BSfZ//8cgOnt5d5Ds96SRFGroBw0g8RXV28noRcLuEZM49Vag0QJHGwEA+aUykNEzNibalRurJfBLSMPak0prAYrFcpptbafT08LCvmYdql/PRy1fy0w+eT41P8udv/izfPutNufdZvlx9hy+9RDKdJZnJUpnRtkxVaaRlrpV8T4+yyXTmXb0ann9eXft6IfHw1kOcnhmkeaSftQd3sTGhf6dLlqhbnUHlxFc8hCUNUMHvj35UrQA+/nE1dtFFqs9NQRO16WAwmmIkns7LnOKpp2DhQiqrK1RMo4TuqYbKsLNCdCa6BQtySqNCX+RzqDQODMVorS5zJsCJSMO40foWLJrcPbVvH9xzz/jxb38b/uM/xg0/slX5zi/e80f1Q25tVavRvXvz9nuGXPaUNORulEZ5eS4t0u2eMp/j5JMZKqviuXt/q1RAZ6eKcyxblq80YmlqfWp1PSlp+I17ahLSANJV1Ty6f4zXnbSARQ0VfOSOPzIcLWgzf9JJakLXNQQjsRQ1SR1ENk0HJ4DJnnKaFsZi+YHwiZTGkdxT4MQ1RuNpqpNR9dpmtX0EBP0+1ardKA0TT6mtdT5LbP8B/v6Mt9FJlD8/fxmnLqrj3vKtvG7rY3zx1e/mod164RYIOBlUUVMXkY7n7J+CLXlKwxTraTuSq1bzibPfyecuuZFk5yp6hmNs6h7hkkZ1Tk/q38OW/rhSTiY5wq00PKzRAEsaCrffrn7I//RPaoUBijRSKTXJzxC7+9TKK8899fTTcPbZlJt9wktEGr2675SDAwfUDyAczimNsMtlNEfoHozl4hlwRKUB0Lv4hMmVxjvfCddcA1/8Ym7se99TmUKf/GSu8EzjD7v6WdFcyaJ923OrP6M26ury2pGHAj6khFRNQSC8sVH939amzlc8rn7YixczHEvxr2ONXPj+7/Kms25k15kX5bKiVq4c556qMav7ydxT+ntyAvNHII1nz76MkXiaq09eyL9fdxqHRxN8+mcvktfWzWRQaRfVaDxNTWxUKSjTAHECjMtYciuNysocGRjSMJPtkdxT4CKNFDWRYUW2vsmnKWeiLiSNujr1m25q4tZuH111rXyhedhZtIRWLOMrv/wqJ8f7+PAdf2TzAa1QdLFdRNdFVCb04nEKpBF2p9xCjjRaW0mms9zkW8NdJ1/O99e/gXd21/O/z6oOEZedpBYN60SUZDrL9kOj6lrs6MiPaVj3lMdIJFTL5bPOUhOPwfnnq1XnUbiocum2mjT6+9UFdNZZVAT9ahVTMvdUwpmIAadGA1yt2s1e2HNJGkMxFrozp/btUytw16Y6kIu99LUtPjJpPPoo/P73anL5zGfU/hEPPKAIY9kyNYH89rd5h/SOJlQ226FDuRWuIY2CScFJc610KY3+/lxA2aiDgwdh/342Ll7DBf/8CF97qofTelWLij+cdGHuBTs7lXvKuIRiKWpSsfzXmgCO0shopZFIqNbZRUjjkVXnEvAJLuxs4tRFdXzk0k5+tfEgm7pd11kBaYzEU9SMDU1qB7hjGnJ89pRbaQwOjlcaiURuYi9UGjoYPhJLUT3UPyXXFOjWHW73lJs0gP3LV/Ot+nW8cdMjnLPM9R2vWEF5OsG3y3dTWx7kvT/YoBTZmjWwdy+RQXW+KuOaEM1i4Yi2uIr7wCGNVEsrH/rJczw06OPzD32Tf7/nSzw/kOLLv97O4oYKTjhLZbSdXK9IYVO3JjBXgV8kkabSuqc8xre+pVa7X/xi3s5k1NUpv/RRkMaevohKt63XK3jT+fTssykP+UvunhrXd0qThpNy6wuqFfEcuaeyWUnPcGx8um17+7jVpKM0mtqPSBryH/6B5MJ2Bh97ih3vej9/+MaP2fFnN6kJ8amn1CTyy1/mHTMUS1IXFGplXKg0CklDd5ZNVGjiN0rDkIYJsm7aBNEo36pejU8IfvlXF/CDQw/TPnyIPzS79sVYuVK9r3ZpjcTT1MQmbyGSZ0vKlard31+UNH5Tu5SzljVQXaYy0K4+Wb22s5IGNQG2tcHGjWSzkrFEmpqh/imRhsmeclJu3dlT7kD44OD4mAaoxUImc2SlMXB4GqThywXCIde2Q7sav3rKNYhslk/87gf5NShr10JlJS2vOpdb3nwyPcNxnts36ATDI1tV/ClvA6ZJEDJxsAKl8febEzy4+RCfu+pEbnjxAa4Ze5k7/+Jc2mrLeMsZHYiWFjjvPJZcsJ7qcICNhjRctRoqe8pbpeHtu3uNsTG4+WbVTdI0B3PjwgtVg7dkMue2mgZ290dpry/P+e+fekoR0/r1VP6hm1gyg/T7EWVl+aTxxBNqEnrf+2b4wcZDtUUvUBo6CBcO+BAC4qbTrVtp/OIX8M1vqol3Cm6CI+HwaIJURo53TxW4pgAaKkIIAb21utlcNpv3/g+9dIiP/GgD0fUfQZ7pg3/9A7RdDddfTW0yynMfOx9/c7OqmbjvPtUKXC8KhqMpak2QdRLScDrLShTBm5iGCVCaCeippxgsq+bXiSrecW47axfWwimncN5LL/JQ02VksxKfT+RlUKVbF6iJOjuk3EGTTEiOLUZpaAw2tvKB257gvRcs59KTT2Z/cwfbs+W87cRcdfnihgrKg362HixYnOhg+GgijZRQPXAYlkxOGsY9VbS4r6Ii912ZTYTc7inI9Xxyk4nf75DGSDRFdXwMVq2f1BZlj1BBeUMaJg5WV8eWnhF+Vr+KG5/6X9pG+/NJo6lJLQT8fhZrd/JQLOlk1EU2vgS0UzmmJ/ApxjRS6XylIX0+Htg1xDWnLuTdF65QZNjezmmL6/nDp16TO/jxx/EBa297go1dLtLo7kamUjp7yioN7/DDH6qL9Oabiz9+0UVqBTXDLVALGxXy9NNK9lZXUxEKkM7K3ATgdk/953/CX/+148I4WvSNJYilMrmMJSnVSkz/eIQQlJt9wgvbo99/v3L3vPDCUdvRrRvidRilMTysaiOKkEbA76OxMkRvZb2adAo6oN7zwgFCiRh/+fx9/L9XL+Pvrl7D164/jb96zQkMhyrYKvR5v+oqVailc+4zWcloIk1tWruEDGksW6ZWxwXuh9zq3tV/yq00zKr86af5+dpXk5SCt63Xn+fyyzlveC9DKdhyUH+/Zje+HTucAraaYb26n6TKN2+DHxdp3BdcyJMvD3DTj59jQ7qC39ytMrYudpGGzydYuaCabYWksW4dvPQSI0Nqwq/p7Zma0jDuKXedxtiYIhC/X03egUCu9sXtnoJcd1kz7vMpxXToEKlMlnhGUhOPTEtpJN3bz5rkhNpa/uWBrVSLDB988n/UWGGQX8ew6sqVKhuKplQcYelSIptVinzFqK5ed533SW0xSmPvXg4uWclANMXpi/XnveMO9TtH/f4KK7xP7qhjy8FRpZ6WLIFMhvi+bqTEc6VxfJNGV5e6EM4+u/jjF2pf9AxcVFJK9rhrNKRUSkO/lxN8Ni4qt9I4fFhJ/Vkqsnt2r3qdUxfVqYGBAaWeXCuuipA/t6eGW2mYQHXBvskzgWmI1/6HR5Sya2pS30HBVqIGTVVh+kL6/LlcVNms5A9berh46xN87OJl/OWVa3jPBct4wykLeduZi/I+M1ddpW71fhKj8RRSQq3xURvSEEL9kD/96TwbQnpCcfpP9fWp78WQRlMTBALIp5/mzpMv56SWCtYs1BPL5Zdz7q9+AsATuzQRL1qkVMX27YzEldqpGTg8aRAc1MTvdN11TV73xqpY2ljBwrpy3vODDdz5fA9LGitY7k7AAE5srWbbodH8YPjVV0M8zsg/f0XZEhubImkUqQiPRHITpRCKEArJwdyacffKXbcScarBQ77cRkSTwCmoM0qjpwfKy3mia4zfbOvlptoRtYVtfX1uj40C1LhJA+CCC4jsUKRXNTSQq16fBE4g3CiNbJZNK1SF97p2/b2tW6f6S02Ade21uWC4zh6L7FEuqiqrNDyE6f0/0YXQ2qrk+7/927jdvCbDQCTJaDzNEqM0du9WK/izzgJcW75ORBqQ13MGmDCFdDI8u3eQkN/HunadAeRu2qZRFtSk0diYTxrGhocemvb7FsKpBv/w+5V74mMfU0HsT36y6PObq8P0Cu0WNOQFbPv1Y/QnJeeN7oebbso7pr2unAU1ZWzYo0mjo0Pt9KbjGsMxNSHURrT0dwfgr7hiHIG5C+oydfV8rGY9t592FbJRk4bPBwsWsLGsia0ty3jbOUvzjl9QW8bypkr+YEjD51NqY/t2RmJaaRyevBW5QaigrUlPdSPPDMObTu/g9j8/i1DAx+YDI1y8qmXc6nXVgmoGIkln50RA9Vn7yEcY/ekvlC2JKZKGqQgvdE+5GwvW1Y2vsje3he4pcKrCR36jFmnVV1w64QRfiHExjQMHoLaWLz24lbbaMm7o1HZNsrFUTVnAuUa44AIicZXZVjHUNyXXFKjrdiSeZkAGnLll88JOVde3YHKlAnCS/q1u6h52SCO6Ty2crNLwEoY0joQf/1jdXnTRtNJv9+jMKWe1Z47VSsOkzTn9p9zuKUMarpbIgCKMW26Zsg0GG/YMcFJHrRPwdhf2GZQH/bmYhts9ZSbr3/8+P3U1mczffAhUivLrXw8f+UhROw4MxagL+5V/2GQ6XXDBhLGSpqowfRnd0O7P/kz1Bfv1r3n8HxVxnn/rF3OrOQ0hBGcsrWfDHhfxXXUVPP44DA46E0LdiH78CF1lweWeSmd4tm0V/7toPZ+9/APcMNzBYd03irY27jz5csKZJG84rWPca5y7opGnXu5XkxrkSEMrjdoDk7cQMXBIQyuNX666AAlcfXIbixoq+K93n8kpHbU5F5kLJy5Q52qci+qWWxhZrTKpahLRKdkSdJOGOxDu/j3V1eUC0hMoja3Zcj561/NKcWvSGP36N5Qtr71sUjvc9qTSMs89Ndy0gOf2DfEnZy+mrEN/pkkaMdZVhBiK6hToCy8kElSvV9V/eMqkce4K5eL8w+4Bh0Q31S9ieVPllKu5F+m4X89wXLlOq6qI/O5xgFd+TEMI4RdC/FEIcZ/+v0EI8ZAQYoe+rXc999NCiJ1CiG1CiCtc42cIITbqx74mStXCcSqksW6dmnDq65VLpSB9cyK83FuQbvv00+qC1ivZiqBRGul8pSFlrp+QW2lIqVZt3d3TqpCOpzJs6h5h/VLXis4ECV0/ICeby600RkaUD/+iixRhuHtxvetdytf6xz/mxj7xCeUG+u53VVplAboHYywM6YnTtKU+Apqrw/RGUsinnlKtvW+6Ca64gsdXnsXy+jBta4vL+zOX1HNgOO4oG66+WsVFHnzQcT3UDvWq73SSBAd3Qd0DzScSSqf420e+w9ORAJf+66O85/vP8E+nXMs9qy/idYM7VEuQApy3oolIMpPLhlm3DnbsYGTnHgBqhvqm5J4CU2yYy566d/VFrGurZnmzuo7Xtdfyi7+8IOcic2HVRKQRDjPy4Y8qW+Jjk06skHNPpY17yuxFUkgaBoYsamrU6vvllzlQ3cQNv9zLT5/rZuvBEaX69uxhZJtSIdU1rk4KkyDo96k9y13ZUzsWqutjzcKa3Gea5LPVVwQZMkrjxBOJ1DYgpKS8b+qkcXJ7LdVlAR7b0ecsal4KN+aU/hQQ8PuoLguo67WsDP7sz4g+8ihwbCiNDwNbXP9/CnhYStkJPKz/RwixBrgOWAtcCdwqhDCU+Q3gRqBT/105C3ZNjqmQBiimf+wxdcF96ENTClDv7osQ8Ak6TKbQU0/BGWc4RV4TuqeGhlSFOuSTxsBA7jkmdXcK2Ng9TDKTZf0S1wVfxD1VHvSr1V5Dg1oxJhKwfz9joXK2v+3dym7jotqxA+66S/n2L75YNcj78Y+VG++ss9R5LUKu3UMx2jNanRzBn2vQVBUikc4ytrxTxVTuvJPke9/HU+1rOH/VxBXL65eqz+qojTPPVLGHe+/Nuaf6Do6rDSkGU1CXSGd4sHIxF+z5I+995ufc99pWXr2qha7BGP/VsI7Rsir+hINFX+Oc5coeJ65x001QXc3If/0QgJpEZEZKY39tKy8sXMXVp06NcBqrwjRVhcdnUAEjNWp1XHP+2VMiDb87EG5W9/39491TBu6Ad309w1kf737b5+mNqFX9QCTpqL7RDpWZVlM2noAnwjj3VDrN9ibl1ulsqVbBb59vUnKurQjlYho+H5Ely6hMJxBTbFYIasI/d3kjv9/Rh6yqor+8hgOijLVFiPxIqKsI5lTPhz5ExK8WOK9opSGE6ACuAr7jGr4G+IG+/wPgWtf4HVLKhJRyN7ATOEsI0QbUSCmfkCpCd7vrmLnFVEkD1EX3qU+pVNjHHpv06Xv6IyxuqFCpiamUysDS8QzIuadihe4pd5aQ2z1lfMOgVMsU8YyeOM9Y4lIaPT2KqFw/8PKQyz0FiqT27+dbZ7+Zq7paOHzRpblg+Fe/qlboTzzBwY4V3PuBz/Ls3/6LShz4v/9TP9xf/CLPDimlqgaPDKhjp7CyNinCvaMJtTp929t4/m9uIZrKcv4JTRMed+KCaipC/lww3O+HK6+Ehx5iSO/TUHeoe2qkoWMaz+0dottXwZXbnwDghOVtfO3603jwry9iS8Xz/PHfr2f9guIr48aqMCcuqOYPu3TPqtZW+OIXGdmtXH/TIY1wwMfTuwf4zye7+PbZbwLgqpMmn+QNTiyWQQWOq6zqnp/lVcRPBKciPJvNxR36+oorjUAgbzzd0Mj73/g37K5v55Y3qUB3/1jSyWoaedPbAagum/qKepx7Ctheq/aKaa8rV8kHP/uZWvQdAXXlwVxMA4gsXERFPKISNqZIGgAXdjbRPRRjX8tiNrcqVb1u4dSVBkB9RSinejo7iZ5zHgAVZKf1OrONo1Ua/wZ8AvI+RauUsgdA3xqncTuw3/W8Lj3Wru8Xjo+DEOJGIcQGIcSGXuPCORpMhzQArrtOBSC/8Y1Jn/pyrytzatMmtXJ3k8ZESsOQRjCYrzQMaVRVTSu28uyeQZY3V9IwQWGfQbk7EA5q1bhvHy8s6CQl4X/OeyM8+6xSGd//Pr94z6e44JFRzrn6H/jQFR/mL17/SbJ33qk+yxVXqF5QLkU2HEsRSWbo6OtSDeGmMDGZAj+zgRTA4zv78Ak4d/nElbkBv4/TF9fnguGgXIu9vYzsVa69mgP7pkQapsbmnhcO4ENyyU597l2puf6FbdTHR4umDhucs7yRDXsGyWb1ObnxRoaXdeLLZqhMxqbsnrrxohXUVYT40oPbuf20qzhteH/+Xi2TYNWCarYfGlX1FS6MxtXudGYb18kwrjU65O+bDvlxDJfH+cnlp/HEklP43Is/5fWnKLLsiyTUfh/f+AYjZ6jfyXSVRtKtNIAd5U10tlSp+hiAN7xh0vOct7oHIk2tVCVjauE3DdIwi5rfL1zL5tblAEVdhke2JcSgq19Y5EqVCVj56/un9TqzjRmThhDiauCwlPLZqR5SZEweYXz8oJS3SSnXSynXN7urYGeK6ZJGZSW8+91w993j6gbcyGZVuq0Tz3hWn6IzznCeY1JuIyamEY3m1yOcckpx0rjmGuWeyk6+2shmJc/uG2T9ojoVcP7sZ9VEPgFpOHUa4CiNLS2qwvgnwUVkJfCOdzCagb9rPJuqcIDPXr2GD796GX3lNbyUrcjZ2N2dV9/ipNt27ZpSPANcTQtd2T6P7+zjpPZaaiuOPKGcsaSerQdHGNUraFO8ObxjN+GAj7Ke6SmNfQNRzipL0hgbUdeBO6vHqIQjkMaSxgoS6Wxu5ej3M3LpFdQkIuoHMAWXEMBbzujgVx++kKf/5hL+7ckf8KVDk6teN1YtqCaRzjotbgxGYqnprexNTCPrWt3H48WVRsEe2i/qlffVY3soD/mpCPkZGEuqBdn7389oUl3bVdOwp72unK7BKNFgroB1e6CGztbqIxw1HkZpGHKPVNRQkdbX3zRIY1lTJe115TzeuIJNrSvoqPTnOkxPwxY3gUVPUBs4VXz3tlmr4ZoJjkZpnA+8QQixB7gDeI0Q4r+BQ9rlhL41s2sX4P5VdQAH9HhHkfG5x3RJA+D971erju9+d8KnHBqNE09lc0rj2WfVD8I1WTr9ngp37zOksX69mtxNQHn3bjauPJ3nz79SPc9sFQnw5S+Pa5UB8HLfGEPRFOvLUyqY/4UvwHvfq6R2IWkY95RZQQ8M0Nd1iN6qBk5dVEdXNMvv15wHGzZw+3UfZSSZ5UtvOYU/v2AZ7zxffa5Ht2v1d9VVyn/sclE56bY7Nk4pngGuViJ6L5CxRJrn9w9x3hFcUwbrl9aTlfDHfUNqYNEiWLmSoa5DqohreHiKpJFTRFcYcdFU8P6XXKIKRIt1FZjgswCMVNer1fQJJ0z7OmypKePaN5zDCe+4dlrHTZRBNRJPTWtl73eURjafQIvFNAom2021HSwaOkhttSKbxqoQ/ZHc5DgST1EVDuQ6Mk8BF3Q2kcpInupVrzNYVk2vCLOydXrntbYiRFbCaELFFSPpLJUmuWEapCGE4PwTGnm8qoONCzpZ2zY9lQE6KO9WGindPPHZZ9Tv2SPMmDSklJ+WUnZIKZeiAtyPSCnfCdwD3KCfdgNgZo57gOuEEGEhxDJUwPtp7cIaFUKco7Om3uU6Zm4xNjYuZXNSnHiiCv5+61tKGRTB7t6CdNvnnlPZPy6JXulOuXX3nzKkcfrp6rZLee4yu/fw/iv/mr843ERG+HJxjd27VdbS5z8/zg7jnlk/prOt3vIW1f11z57i7im30ujvZ+ug+gF++NJOGipD/ORV1xEJlvGdxedy8apmTupQPtrm6jDr2mt4dJtrF7nzz88nDaM0Du6dstKorwjhEzml8fTuftJZyQVTII3TFtfjE+Sn3l56KcODo9QG9CptGu4pgCsWayVVSBplZfA3f3PEzrDNVUVII56mtqPVqVafNj76UfWdTgOdLdUIwbhg+EgsTU351Ff2gcKGhQYu8uurrOfyP/9PfrP4lLxjN5Y3c9LBnY4CaagM56nJ0XiammmoDIAzlzYQCvj4/T71uZwg+AyUBuC0kY8k0lTW6teYBmkAXNDZzIg/zL76NtYtnfyaLURtRYiReMpxJUYTaQRQtmLpnOxmOVXMRZ3GLcBlQogdwGX6f6SUm4G7gJeAB4CbpJRm1v0AKpi+E9gFzL3TTsqZKQ2AD35QBanvL27my32udNtUSrXgMCSgYfo9xYx7CnKk0dCQm1i1i+r3kRDd5fUcimX43ZrzcqTxrW+pz/LMM3nbZQJs2DtIY2WIZbv1pPS976nWBUKMm7jLdUW4NK6EgQG2JtQP95SOOt56RgcP1S7jq3/1FQZT8KFLOvOOv6izmef2DToBVa65Ru1ct2cPoGo0ynzQEBuZstLw+wSNVWFnov3ttl7Kgr78oP4EqAoHWN1Ww4a9+XGN4UAZdaaP0DTcU6d01LKwtU4NFpLGFOAojbFcrctILKWqkAPTmyCPBuUhP0sbK49aaYxrjW7gUhr/OljN9uYl/LJljTM2HE2x31fBOhdpNFWGVPaUsSWWchotThVlQT9nL2vgsZcHIBh0SGPldElDuz0HtVsomsxQ2daiYnBTXOwYnLciF/da2zG9IDgopSFlriA1ksxQGQ4gtmyBt71t2q83W5gV0pBS/lZKebW+3y+lvERK2alvB1zPu1lKuUJKuUpKeb9rfIOUcp1+7C+lLIHDLhZTcYGZkMY116iJ/ac/Lfrwnr4IZUEfC2rK1C5qiURePAOUfK0I+lW/fnd79MOHVeqh2Xhm717IZvlJy8k0yCQNlSEVlH76afW63/1urj/Pgw/mvcdzewc5fUk9YusWVRldXa0Ib9cu1TrchbKgn6yERFmFCsL39fFSsI5WmaChMsTbz1xERsJ3Aku4sLMp10NH41Urm0lnJX/YqdNK3/AGdas3R+oeirEwkFH++2n8+Jqq1CpUSsnDWw5zwQnNuSLFSbCytZq9/a4CxFe/mqHyamoO6Ky0SQr7QJHG4oYK1Z7EuFuOhjTylMb0JurZwirdTsSN0Xh6WjENv08ghGsTJgP9e9p6cIQ7esCfzfBkeU7VbtJddk86tNNZuTdWhVT2lMuW6agegwtOaGL7oTEONrezo2kJVX5YWFs2+YEuGNIwsaexRJrK9gUqxmeaTU4RTVVh1mi31HQzp0ApbcCJa0QSaeXWLlEZ20Q4fivC3b3/p4tgULlf3MVuLuzWjQp9PpELBhcoDaD4RkyGNExQdd8+Du/cx/+tOJO31sZ542ntPNTQSf/23ao2oq9P1Ue0tTl7Q4P6Me8diCqf7ksvqS0mDZYtU5/BBRNjiaez6se8dStbGpdwYpkSg8ubq5yMpQ+9Jl9lAJy+pJ6qcCAX1+jsVO/5858DukYjNapiHUuXTnRmx6G5WimNrQdH6R6KcenqySd6g9aaMg6PxnMZSw0NjNQ0UHtQJ+tNQWkIIXj046/mHWctzu3oNwPSqAoHKAv68khjOOYRaSyoZk9/RLkjNUbiKaf30lQR9Ply270aVFUhpeQf79tCdcjHh/5wB12+CvYPKPI2BY7rDu7Kc0/1RxJOT6zRxPSVBsCFnSo55rFlp7O9aTGdNf5xrVQmQ215/kQdTeg9uafQqLAY3nDqQk5qr6WlZnrkBTjJHiaDyigNr2FJYyakAYo0tm3L7Rftwu6+SH4QvLo6193Uhcqwv7h7qqVF+ccXLIB9+/ifx3eS8fl5++p63rZ+ESl8/Hzl+apuZMUKuPxyeO1rldLQhYGHR+NkspKFNWWwdWs+aRSB00BRB8NTL25kZ9MiVjfmLvbPXLWav71qNWctG+/bDfp9nLeikd9t7801xLv2WtXscWCAnuE4C0d1S/FptJlvqgrRN5bk4S3K9faaE6dDGmFSGem4GgCGyyqpi+vvfgqkAa4upPX1imynWFNR+BqGAA2mG0eYLSxvrkRK6BpUE7mUUrnKpjlR+31CBcIL3FOPbD3MYzv7+Mh5HVy5TS2sntJ7lG/qHqY9JFWKsnFPVYVIZaQTfB6JTU/1GJy4oJqmqhC/X3QyO5oWs7KxfPKDCmCUhsmgiiQzR7Xp0ftftYJ7P3TBjI41SmM4liMwr/cHB0saR0caME5tpDNZ9g1E80njtNOK9ldy0lzd7qne3pzbZPFisnv3csfLUc7d+wLL1y5n1YJqTmmt4H9Ougx5+LDK5vL54HWvU9XkTz4JwIEh5TtfmB5TFd6TkYY7m6uhgV1jWVL+IKsX5whiXXst771w+YSv8apVzXQPxdilEwG49lrIZEjd90v6xhIs6O2etl/YTLT/t+Uwp3RMb8W2QD/3oO4RlcpkiRCgNq4TIMqnOamUlamslQ98YHrHaTRXhZ1mgcl0llgq44nSMF0KTBp0JJkhK5k2gQX8YlwgPF1Ryc2/2sLy5kreedlaVt76ZerLAzz5snJbbuoe5iS9M50hjUa9S6NxUY3O0G3n8wkuOKGJhxeuo7+yjs4pNgd0o9bV6TZmspU8Wt3XG6URMUrD+/3BwZLGzElj/Xq16ixIfesajJHOSkUa6XTRILhBReHufYODqqjOkMaSJTweK2N/ys/1LzzobPzztnOXs7VlGS8uXqMa+YHabCgQcFJve4bVhNB2WLtiJiGNMqcXliKNrbo+Y/WJE9ceFOIi7R5wXFTr18PChRz+5UNICQu6dk05CG7QXBUmmcny/P4hLlk9NWVg0Kr92YdH1ETttBBJx6esMsbhzDOnn3Gn4VYapn5kui6h2UCH3kmyS6dBj+jzMt2JOuj3kc7mp9z+Jhrm5d4IH7tsFUG/D99b38LZy5t48uV+RuIp9vRHOWntEtXU8uKLAeWeAujXsauRacZX3Liws5mxoLJn5eLpuxGDfh9VYdXzKaKVj1d7ctdpV5k7KF/hcQsRsKQxc9IoK1PB7QKlsVtnTi1rqlRuoVhsXBDcoCIUyDUshFwBnyaNscXL+KeVV9CQiXPF2F4npfP1py6kjCzff9enkCYNsLZWFfDpuEaPVhpte7erxychDSemod1TW1qWEcqkWH7C1CqVARY1qD0cnjDtMnw+eMMbOPjsJgAWTCPd1sC9r/kl04hngIppQE5pOB1uO5ep1OkSw00aI3rPiGINDufcjqowIb/PcU+ZjLfpxhECPpHfewr4cXeW5uowl6/NkfLZyxvoGozx4CbVm2vtkkbVikYnFphtiPvGksRSGTJZOWMyvaAzRxQzIQ1Q38lQLKmSVPBu/4rqsgA+4cqeSlil4S2OljRAuaieeSavo2seaRSpBHfDURrhsPLz672EaWkhmc7y/or1bGtazFee+W/CS3Ir/pqyIDe86gR+lmrgSw9uy8UQrrpKpbl2ddE9FKMqHKBm22YV2J6kgj4vptHQwEsty+gcPUQgML0fTGdrVX7G0rXXcjCgVrYLRvunrTRMVfjC2jInE2WqaNGEc0iThimUqvn4X8Odd07rtWYDzVVlDEZTJNPZ3Oreg5iGzydYWFfm1M44OwhO1z3lE3mB8O7qZn7bk+C6Mxc5KbmgWqgAfPcxtSg6qaDbq/mOzR40ML2+U2601pSxKtZPdSLqKM3poq4iyLBbaXg0Uft8gtryYL7SsDENDzFbpJFI5LXL2N0XoaYsoHo9PfecylufIFXP2S0PlNrQG9Nkm5v5xN0v8Fiyglvu/xoXP/pzlfHkwievOJF3nL2YW3+7i39+QBPH616nHrz/fnqGY7TVlqmc7tWrJ03TMyu7b/9+N9vqFrK1eSmr08PTPiUd9RV0DcZyRHbxxfQ0q4L/BaP9M1Yar1k9flOhyRD0+2iqCjmkYSbq2vqqvB5FpYL5LP2RhLN69CKmAdBeX+7ENGbqngoUuKfuPOVyAN5+Zr5Lc1VrNXUVQbYeHGVhbRmN7r3qgfpK9b79YwnHlplkTxn85cgmPrT9oWlfLwZ1uj26IY0qDzOW6l1ddyMmk8tjWNKYAmmMxlN8//HdXPlvv+PrD+/IPXCe6jrpdlGZzCkhhFIap546YXO+8lCASMJFGto99Z3DIX7+/AE+flI1b930sHq8gDR8PsE/XrOOd56zmG8+uov/enyPIocVK+D22+kZjtNWV66qjSdxTQF0tlTx8StW8dzeQa4cW0lvVQMnhtOTHleIjvpyYqlMrlgrFOLQujMIpxLUxUdVs8JpYEljBa87aQHvPGfJtG0BtfI8OKyVhs5CqfPAJQT5tRojHsY0ADrqKpzWLjO1xQmE+3ykw2XcefLlvHpFvRMzMfD5BGfrjLu1RfaUCAf8VJcF6I8kHbfddCvC3Xj9X7+TGz923YyPrytXGzFFkkZpeLe6r9OtRKSUVml4jimQhpSSrz+8g3P/6RE+d+9L7OmPcOeG/blVdGurmqRdwXAn3TaTURsUTeCaAqgM6ZRbUBlUqRQS+O+dY5y7vJEPXpGrpC0kDVA/xi9cs441bTU8vPWQUhN/9Vfw2GMc6B1hYRiVErxmzbhjCyGE4KaLT+D3n7iYDyxI0zF0kIsap395OEFWvYoFOLikkwVj/Yi2tvzeRFNAOODn1j85Y8rbZBZiQU0Zh0wg3GzANB9Iw2z16qHS6B1NEE9lHFum6xIK+nwq5RZ4eNV5HKpu5B3njr9OIeeiKnRNGTRVhTVpHL3S4OST4TWvmfHhtRWqaaFZ0HmpNFSn2yTJTJZ0Vlql4RXSmawiDSGOmHZ562938ZWHtnPeikZ+ftP5fOZ1q+kajOX77M8/X5GGlAxGkhwYjnFCS5XamjQaVcHpCVAR8hNNZRQJ6WD4xvZV7BtK8MbT2hGNjblJtghpgJrs1y6sYcchTYLveQ+Jphb6EpK2hN6jYwpKw6C+MsQnTq7hsW+9l5VLpt9JuL1OnU9n1zzgYFUjC8YGph3PmA201JQ57qlhM1HPB9KIexfTgFza7YGhmMslND1b/DoQnspk+cYZ17BgtJ+LJ8hwe/WqFsIB34T7oDRUhugfSzgxjVqPzguY7rLeZ09BTmlENYFZpeEB7t/Yw9Vff4yXIqgJeYL9qe96Zj9fenAb1566kG++8wxOXVTHBTql9Pc7XQV9552nCvJ27eLR7b1ICRcmD8PHPqb2y37zmye0pTwUQEq1laghjftOu5ygX3DF2gWK1Ew7kSO4dTpbqzg8mlAr6cpKDn7gwwAsfElvxToN0gCUMlmxAs49d3rHoVawkCscAzgYTbFg2UJ43/um/XpHiwU1ZfRHkiTTWYZiSarCgbwgbSnRpOsRlNJIEfAJJwGh1DDk3jUYYzSRpizoy+voOxUE/YJUVvKF+17i+ZYVfPqZuybcj2NZUyUv/cOVE/YNa6xUrURGZ0NpHCXqKoKks5LDOtOtysOMpUJX2XzInvLeghKjLOSnbyzJNYEz+ci5b+PPkml++WIP//3kXg4Mx1nRXElHfQU/+2M3F3Y28S9vOcXZxGVpYwXtdeU8tqOXPzU+dlPk9/3v8/DKN9BUGeSk979TVQ1///sTkhLkVg2RRJqymhqyCO5bfjYXdjbn9otYvFhlVR2hCrmzRRHOjsOjrF/awIFr3w53bWXhT3+iAr5H2OehKBYsyGVyTRO15UFqygKOe0pKyaHhBAsuWA+vnSZ5zQJaa9Tq/vBonOFYyjPXFChXW215kN6xBFkpqS0PzjhYe7To0Bs3dWulMRM3WcDv49k9A/xuey837vgN1xzedMTnH6nVeWNVmOf2Dc3YVTabMPURJrvMy9qI+oogkWTGCYbbOg0PcPGqFn791xdxeXQ/Xzr9TZzy+V/z8btfJJrM8KqVzSTTWR7cfJCzljbwzXeekdcaWwjBhZ1N/GFXv+PLZc0aOPVU0l/8Jx59bjcXb3wU34Fu+J//mbSVcuHufX9sX8WB8jpef4qrbfnFF8Nllx1xp7tOvWfAjsPKRdWDmijbhg6peoQjENdcwGRQgUqjTGayTnV2qWHSLg+NqNW9l6QBuVqN4VjaMzcZQGt1mIBP0DUYnVHfKVApt5Fkhgs7m/jkroenHa9yo7EyxIDOKvNSgUGulUj3UIxQwOeZMgWo0zUsB7S71yoNj9BQGeI/9z7Aa1N1PP6+j/P6k9s4d0Wjs+qTUk64Arygs4k7ntnPi93DqtOrzwfPPMOz9/2OkSdjXDK0W20He+aZk9ph8r9jKUUa9554ESGZ4VK3X/iTn1R/R8DC2nIqQn62686l5gJriwzAmpkHBGeKjvpy9uid4Xp05lLbDHPmjxaGrA6NxBmKzgPS0K3eK8OBo8oQOloE/D4W1KpajZn2emqqCrO0sYKvX38a/u+UQXh6O9O50VilNj/aPxiluizgmQIDnB32TK2TlzCZfiZGOB9iGsclaQAwOsrVmSGuftNJ4x460gV7/oomhIDHdvTl2oMHAjwSaiPo380F994OU7zQjNT8lwe28cbKJfxqVQMXy/5p+3N9PsEJLVXs1ErjwHCchsoQ5Xf+xJPK5476Ch7b2adcUzoI3eqV0nCRxnAsxYrmo6jLmQU0V4d5oWuIjJx51fNsoUPXaiQzWac53nTwlbedQsZk9Jx22lFtQWpqN/b0RTw/L26l0VIdnuTZcwvzvThKw2ZPeYgZbsBUXxli3cJaHtuR39324a2HOXtZ47RWJuuX1HPdmYt4du8AN6U7OVzdyNVV8ckPLILOlmong6pnSBX2ce21npBGe3050WSGwWjKpTSm33F0NlBfESTk93FQk0bdJHuLzzWaq8P06UC4V+m2Bu11yo2o9q+Yvi1lQX9uErv1VqWwZwjTSmRPX8TTeAbkVvfJdNZ7pVEx/5SGJY0Z4ILOJp7bN8iYTsnb1x9l5+GxabXtBpUhcsubT+aZz1zKHW29fP6hb3Jl+8xWNp2tVc7E2DMc92ySBncX1SiHRuL4RC5zqNQQQtBSE+bQcJyheRDTaKoKE0lmODSS8Czd1qCjvpxDo3H6xhKeusog1+k2kvSm868bbgL1epLOkYZafFml4SWOgjQuPKFJ71Kn1MYjW6e/14MbAb+Pc1rC3PDcfQRbpl8bAaqiG2Dn4TG1S16dN+4gyJFG92CMnuE4LdVlE6ZilgILasrYOxAlmc567vowtRpjibTnk2N7fTlSml37vLWlsTK3WPJaaZQF/U4g3utJ2rinnEyueaA0vKctr3AUpHHG0npqy4N88EfPcd4JTRwcjrG8uVLtCT5TmJTaCYr4JoPZC/n5/UOMxtMeK41cVfihkfiMG8fNFlpry3h0m2rXPh/cUwZeE5ghd/CuyNCg3vW9eE1goK6T2HDG82ylipCfoF/Qp/dh8ap5ohszXv4JIRYJIX4jhNgihNgshPiwHm8QQjwkhNihb+tdx3xaCLFTCLFNCHGFa/wMIcRG/djXxFynTkh5VKQRDvj56QfP430XLWdPX4Tth8ZUMd7R4KKLYPNmWLduRoe315VTFvQ5e1l4qTRqy4NUlwXoGowqV5lHQXCD1uoyx5XotXuquWoekUZdrkeU16on4Pc5xOG1LZC7TrxWGkIIJ5urPOg/Yq1LqXA0PoM08DEp5WrgHOAmIcQa4FPAw1LKTuBh/T/6seuAtcCVwK1CCKO1vgHcCHTqvyuPwq7JkUyqDZKOosPtiuYqPnnliTz68Vfz8MdexYcvGb+d67QgxJR6RE0Ek0H1lN4hbWGdd0oDcrUah4bjLPBYaSyozU3UnpOGW2l47IZZUFuGmYO8JjDIZVB57Z6CnCKtnAfFdPXzyBY4CtKQUvZIKZ/T90eBLUA7cA3wA/20HwDX6vvXAHdIKRNSyt3ATuAsIUQbUCOlfEKqToC3u46ZG8xGW3QNIQQrmqucne+8xMqWatWSBO/qIgza68rZenCU0UTac9Jwp/uaal+v0FAZmjcTdSjgc86N1wQG6tyA9+cFcteJ10oDcrbMB9cUzFIgXAixFDgNeApolVL2gCIWwESH24H9rsO69Fi7vl84PneYRdKYTzhBV4YL4V1dhEFHfbmTJuhVNbiB+1x4rTT8PuGsqOeDG8bENeZDHMFk2M0rpTEPAs/GlvkQBIdZIA0hRBXwv8BHpJQjR3pqkTF5hPFi73WjEGKDEGJDb2/v9I01OEZJw/Sgaq0u87T1AeQHWb1WGm7SqvU4EA65uIaXnVwNTNLCfLDFZFDNB9VTWzE/YhrgdpV5bwscJWkIIYIowviRlPKneviQdjmhbw/r8S7A3TmvAzigxzuKjI+DlPI2KeV6KeX65km2Lz0ijlHSWKmVRpuHQXAD90Y880VpCAHV8+CHZ+Ia80FpmG6388EWxz01D2xx3FPzwCVk0m5f8UpDZzh9F9gipfxX10P3ADfo+zcAv3CNXyeECAshlqEC3k9rF9aoEOIc/Zrvch0zNzhGSaOjvoJwwMdCD9Ntc7bMH6VRHvJTUxagpizodCz2Eg5pzAPf/ZXrFvCm09vHbcHqBXLuKe/Py3xa3ZvsqflAYHB0dRrnA38KbBRCPK/H/ga4BbhLCPEeYB/wVgAp5WYhxF3AS6jMq5uklHqvUz4AfB8oB+7Xf3OHY5Q0/D7BZ65a7dRseIlFWmnUVQTnRZJAa00ZSdOZ2GOc0FJFS3V4XpyXde21/OvbTvXaDABOW1zP8uZKFjeWfv/2QphWIvOhFbkT05gHtsBRkIaU8jGKxyMALpngmJuBm4uMbwBmVqAwExyjpAHwrnOXem0CoIrFqsIBz11TBksaK50d6rzGey5YxvVnLfbajHmHde21PPKxV3ttBqCIPeT3sbTxKAp2ZwlOyu0xoDReuTCkUe39ivxYhUpFrvTcNWXwxTeuI52deRfW2UTQ76O2/Pjt4PNKQGdrNVu/cOW8cGca99QrXmm8ojGq9p04FpXGfMI33nmG51lcBi3zRPFYvHIwHwgD3Om/82O6nh9WlBpGaVR47zs9luF1VbqFxbGAhnmWPXX8kkZFxRG3ULWwsLCYD2iuDvO516/htSe1Tf7kEuD4JQ3rmrKwsHgFQAjBu8+fWffrucD8cDiXGpY0LCwsLGYESxoWFhYWFlOGJQ0LCwsLiynDkoaFhYWFxZRhScPCwsLCYsqwpGFhYWFhMWVY0rCwsLCwmDIsaVhYWFhYTBnHH2mkUpBIWNKwsLCwmAGOP9KIRNStJQ0LCwuLaeP4Iw3bFt3CwsJixjj+SMO2RbewsLCYMY4/0jiGd+2zsLCwmGtY0rCwsLCwmDIsaVhYWFhYTBnzhjSEEFcKIbYJIXYKIT41Z29kScPCwsJixpgXpCGE8AP/CbwWWANcL4RYMydvZknDwsLCYsaYF6QBnAXslFK+LKVMAncA18zJO1nSsLCwsJgx5gtptAP7Xf936bE8CCFuFEJsEEJs6O3tndk7LV8Ob34zVFbO7HgLCwuL4xjzhTREkTE5bkDK26SU66WU65ubm2f2TtdcA3ffDcHgzI63sLCwOI4xX0ijC1jk+r8DOOCRLRYWFhYWE2C+kMYzQKcQYpkQIgRcB9zjsU0WFhYWFgUIeG0AgJQyLYT4S+BBwA98T0q52WOzLCwsLCwKMC9IA0BK+SvgV17bYWFhYWExMeaLe8rCwsLC4hUASxoWFhYWFlOGJQ0LCwsLiynDkoaFhYWFxZQhpBxXQ/eKgBCiF9g7w8ObgL5ZNOdoMJ9sgfllj7WlOKwtxWFtKY5CW5ZIKWdYHf0KJo2jgRBig5Ryvdd2wPyyBeaXPdaW4rC2FIe1pThm2xbrnrKwsLCwmDIsaVhYWFhYTBnHK2nc5rUBLswnW2B+2WNtKQ5rS3FYW4pjVm05LmMaFhYWFhYzw/GqNCwsLCwsZgBLGhYWFhYWU8YxQxpCiO8JIQ4LITa5xk4RQjwhhNgohLhXCFHjeuxk/dhm/XhZwevd434tL2wRQvxWCLFNCPG8/mvx0JaQEOI2IcR2IcRWIcSbvbBFCFHtOh/PCyH6hBD/5uF5uV7//6IQ4gEhRJOHtrxd27FZCPEv07VjurYIIf6k4LvICiFO1Y+doZ+/UwjxNSFEsY3WSmXLzUKI/UKIsZmck9m0RwhRIYT4pf4NbRZC3OKVLfqxB4QQL2hbvimE8E/65lLKY+IPuAg4HdjkGnsGeJW+/+fAF/T9APAicIr+vxHwu457E/Bj92t5YQvwW2D9fDgvwOeBf9T3fUCTl9+R6/hngYu8sEWPHzbnAvgX4HMe2dII7AOa9fgPgEvm0paC404CXnb9/zRwLmpXzvuB13poyzlAGzA2XRtm2x6gArhY3w8Bv/f43NToWwH8L3DdpO99NCdxvv0BSwtO4gi5YP8i4CV9/3XAf0/wGlXAY8AaZkgas2jLbzlK0phFW/YDlfPBFtexndou4YUtQBDoBZboH903gRs9suVM4P9c//8pcOtc2lJwzBeBm/X9NmCr67HrgW95YUvB+FGRxmzbox/7d+B9Xtuir+V7gbdP9r7HjHtqAmwC3qDvv5XclrIrASmEeFAI8ZwQ4hOuY74AfAWIzgNbAP5LS8q/m4nEnw1bhBB1+vEv6PH/EUK0emFLAa4H7pT6qi+1LVLKFPABYCNqe+I1wHe9sAXYCZwohFgqhAgA15K/hfJc2OLG24Gf6PvtqC2cDbr0mBe2zDVmbI/+Xb0eeNhLW4QQD6IU8yhw92RvcqyTxp8DNwkhngWqgaQeDwAXAH+ib98ohLhE+/lOkFL+zGtb9GN/IqU8CbhQ//2pR7YEUPu2Py6lPB14AviyR7a4cR2zOzlM93oJokjjNGAhym30aS9skVIOalvuRLk89gDpObYFACHE2UBUSmn868UWN7NF7NO1Za4xI3s0sf8E+JqU8mUvbZFSXoFSh2HgNZO9ybzZuW8uIKXcClwOIIRYCVylH+oCHpVS9unHfoXyD44BZwgh9qDOTYsQ4rdSyld7YMvDUspufeyoEOLHwFnA7R7Y8ghKeRky/R/gPUdrxwxteVj/fwoQkFI+Oxt2zNCWEX3cLj1+F/Apj2x5WEp5L8rFgBDiRiAzx7YYFJJ3F2qRYdCBUmJe2DKnOAp7bgN2SCn/bR7YgpQyLoS4B7gGeOhI73NMKw2hs42EED7gb1E+Z1B7kZ+sMxkCwKtQ/r9vSCkXSimXolZx22eDMGZiixAiIHQmjl7RXo2SnyW3Rbt/7gVerZ93CfCSF7a4Dr2eWZ4cZmBLN7BGCGE6hl4GbPHIFvcx9cAHge/MsS1m7K3AHWZMStkDjAohztEu1XcBv/DClrnGTOwRQvwjUAt8xEtbhBBVQog2fT+AipdtnfSNjjYwNF/+UBNID5BCrXTeA3wY2K7/bsEVMAXeCWxGTcT/MlmQqdS2AJWozKAX9WP/TpHsoVKdF1Sw93fanoeBxV5+R8DLwIleXy/A+1FE8SKKWBs9tOUnKAJ5iSlkwcySLa8GnizyOuu1fbuA/3Af44Et/6KPz+rbz3l1blCqS+pr5nn9916PbGlFZVyZOebrKPV+xPe2bUQsLCwsLKaMY9o9ZWFhYWExu7CkYWFhYWExZVjSsLCwsLCYMixpWFhYWFhMGZY0LCwsLCymDEsaFhYWFhZThiUNCwsLC4sp4/8DQsOaW/e0NGAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ploting graph\n",
    "plt.plot(report,color = 'red')\n",
    "plt.plot(fullraw['Month'],fullraw['Sales'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
